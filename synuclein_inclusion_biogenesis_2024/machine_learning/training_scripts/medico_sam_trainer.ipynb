{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840f7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Union, Tuple, Literal\n",
    "\n",
    "import torch\n",
    "\n",
    "import micro_sam.training as sam_training\n",
    "from micro_sam.training.util import ConvertToSemanticSamInputs\n",
    "\n",
    "from medico_sam.util import LinearWarmUpScheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10f4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrayscaleSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, patch_shape):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.mask_files = sorted(os.listdir(mask_dir))\n",
    "        self.patch_shape = patch_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
    "\n",
    "        # Load image and mask\n",
    "        image = Image.open(image_path).convert(\"L\")  # Load as grayscale\n",
    "        mask = Image.open(mask_path).convert(\"L\")    # Also grayscale but should have class labels as int\n",
    "\n",
    "        # Resize to patch shape\n",
    "        image = image.resize(self.patch_shape[::-1])  # PIL expects (W, H)\n",
    "        mask = mask.resize(self.patch_shape[::-1])\n",
    "\n",
    "        # Convert to tensors\n",
    "        image_tensor = transforms.ToTensor()(image)         # (1, H, W), float in [0, 1]\n",
    "        mask_tensor = transforms.PILToTensor()(mask).long() # (1, H, W), integer labels\n",
    "\n",
    "        return image_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba49611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sj1205\\AppData\\Local\\miniconda3\\envs\\medico-sam\\Lib\\site-packages\\torch_em\\util\\util.py:299: UserWarning: Constructor arguments for <class 'micro_sam.training.trainable_sam.TrainableSAM'> cannot be deduced.\n",
      "For this object, empty constructor arguments will be used.\n",
      "The trainer can probably not be correctly deserialized via 'DefaultTrainer.from_checkpoint'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sj1205\\AppData\\Local\\miniconda3\\envs\\medico-sam\\Lib\\site-packages\\torch_em\\util\\util.py:299: UserWarning: Constructor arguments for <class 'micro_sam.training.util.ConvertToSemanticSamInputs'> cannot be deduced.\n",
      "For this object, empty constructor arguments will be used.\n",
      "The trainer can probably not be correctly deserialized via 'DefaultTrainer.from_checkpoint'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sj1205\\AppData\\Local\\miniconda3\\envs\\medico-sam\\Lib\\site-packages\\torch_em\\util\\util.py:299: UserWarning: Constructor arguments for <class 'micro_sam.training.semantic_sam_trainer.CustomDiceLoss'> cannot be deduced.\n",
      "For this object, empty constructor arguments will be used.\n",
      "The trainer can probably not be correctly deserialized via 'DefaultTrainer.from_checkpoint'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting for 17900 iterations /  100 epochs\n",
      "with 179 iterations per epoch\n",
      "Training with mixed precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/17900 [00:00<?, ?it/s]c:\\Users\\sj1205\\AppData\\Local\\miniconda3\\envs\\medico-sam\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"data\"\n",
    "\n",
    "\n",
    "def get_data_loaders(data_path: Union[os.PathLike, str], split: Literal[\"train\", \"val\"], patch_shape: Tuple[int, int]):\n",
    "    image_dir = os.path.join(data_path, split, \"images\")\n",
    "    mask_dir = os.path.join(data_path, split, \"masks\")\n",
    "\n",
    "    dataset = GrayscaleSegmentationDataset(image_dir, mask_dir, patch_shape)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True, pin_memory=True)\n",
    "\n",
    "    # Manually add .shuffle attribute to make it compatible\n",
    "    dataloader.shuffle = True\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "def finetune_semantic_sam_2d():\n",
    "    \"\"\"Scripts for training a 2d semantic segmentation model on medical datasets.\"\"\"\n",
    "    # override this (below) if you have some more complex set-up and need to specify the exact gpu\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # device to train the model on.\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # training settings:\n",
    "    model_type = \"vit_b_lm\"  # override this to your desired choice of Segment Anything model.\n",
    "    checkpoint_path = None  # override this to start training from a custom checkpoint\n",
    "    num_classes = 3  # 1 background class and 'n' semantic foreground classes\n",
    "    checkpoint_name = \"oimhs_semantic_sam\"  # the name for storing the checkpoints.\n",
    "    patch_shape = (662, 662)  # the patch shape for 2d semantic segmentation training\n",
    "\n",
    "    # get the trainable segment anything model\n",
    "    model = sam_training.get_trainable_sam_model(\n",
    "        model_type=model_type,\n",
    "        device=device,\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        flexible_load_checkpoint=True,\n",
    "        num_multimask_outputs=num_classes,\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    # all the stuff we need for training\n",
    "    n_epochs = 100\n",
    "    learning_rate = 1e-4\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.1)\n",
    "    mscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.9, patience=5)\n",
    "    scheduler = LinearWarmUpScheduler(optimizer, warmup_epochs=4, main_scheduler=mscheduler)\n",
    "\n",
    "    # Get the dataloaders\n",
    "    train_loader = get_data_loaders(os.path.join(DATA_ROOT), \"train\", patch_shape)\n",
    "    val_loader = get_data_loaders(os.path.join(DATA_ROOT), \"val\", patch_shape)\n",
    "\n",
    "    # this class creates all the training data for a batch (inputs and labels)\n",
    "    convert_inputs = ConvertToSemanticSamInputs()\n",
    "\n",
    "    # the trainer which performs the semantic segmentation training and validation (implemented using \"torch_em\")\n",
    "    trainer = sam_training.SemanticSamTrainer(\n",
    "        name=checkpoint_name,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        lr_scheduler=scheduler,\n",
    "        log_image_interval=100,\n",
    "        mixed_precision=True,\n",
    "        compile_model=False,\n",
    "        convert_inputs=convert_inputs,\n",
    "        num_classes=num_classes,\n",
    "        dice_weight=0.5,\n",
    "    )\n",
    "    trainer.fit(epochs=n_epochs)\n",
    "\n",
    "\n",
    "def main():\n",
    "    finetune_semantic_sam_2d()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medico-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
