{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sj1205\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\cellpose\\resnet_torch.py:275: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(filename, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import gaussian, threshold_otsu, threshold_multiotsu, sobel\n",
    "from skimage.morphology import remove_small_objects, disk, binary_closing\n",
    "from scipy.ndimage import zoom, binary_dilation, binary_erosion, distance_transform_edt\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import io, exposure, color\n",
    "from skimage import measure, morphology\n",
    "from skimage import exposure\n",
    "from czifile import imread\n",
    "from cellpose import models, plot \n",
    "import cv2\n",
    "import re\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "model = models.Cellpose(gpu=False, model_type='cyto3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_INCLUSION_SIZE = 10\n",
    "MAX_INCLUSION_SIZE = 2000\n",
    "RADIUS = 15\n",
    "COLOR_SCHEME = 'hot'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, path, type):\n",
    "    \"\"\"Display the image.\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{path} {type}\")\n",
    "    plt.show()\n",
    "\n",
    "def show_image(image,cmap=COLOR_SCHEME):\n",
    "    io.imshow(image, cmap=cmap)\n",
    "    plt.show()\n",
    "\n",
    "def extract_image_paths(folder):\n",
    "    \"\"\"Extract all image file paths from the specified folder.\"\"\"\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"Read the LSM image from the specified path.\"\"\"\n",
    "    return imread(image_path)\n",
    "\n",
    "\n",
    "def count(mask): \n",
    "    \"\"\"Count the number of unique labels in the mask.\"\"\"\n",
    "    return len(np.unique(label(mask))) - 1  # Exclude background label (0)\n",
    "\n",
    "def extract_channels(image: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Extract green and red channels from the squeezed image (shape: [Z, C, H, W]).\"\"\" \n",
    "    return image[0], image[1]\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize the image to the range [0, 1].\n",
    "    This is useful for consistent processing across different images.\n",
    "    \"\"\"\n",
    "    return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "def calculate_surface_area(labeled_image: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the total surface area for labeled regions.\"\"\"\n",
    "    props = regionprops(labeled_image)\n",
    "    return sum(prop.area for prop in props)\n",
    "\n",
    "def remove_small_objects_only(binary_image, min_size=100):\n",
    "    labeled_image = measure.label(binary_image)\n",
    "\n",
    "    # Remove objects smaller than min_size\n",
    "    filtered_image = morphology.remove_small_objects(labeled_image, min_size=min_size)\n",
    "\n",
    "    # Convert back to binary mask\n",
    "    return filtered_image > 0\n",
    "\n",
    "def remove_small_objects(labeled_image, min_size=10):\n",
    "\n",
    "    # Remove objects smaller than min_size\n",
    "    filtered_image = morphology.remove_small_objects(labeled_image, min_size=min_size)\n",
    "\n",
    "    # Convert back to binary mask\n",
    "    return filtered_image > 0\n",
    "\n",
    "def high_circularity_mask(labeled_image: np.ndarray, threshold: float = 0.7) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return a binary mask with only the regions that have a circularity index higher than the threshold.\n",
    "    \n",
    "    Parameters:\n",
    "        labeled_image (np.ndarray): Labeled image where each object has a unique label.\n",
    "        threshold (float): Minimum circularity index to keep the object.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Binary mask with only high-circularity objects.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(labeled_image, dtype=np.uint8)\n",
    "    props = regionprops(labeled_image)\n",
    "\n",
    "    for prop in props:\n",
    "        perimeter = prop.perimeter\n",
    "        area = prop.area\n",
    "        if perimeter > 0:\n",
    "            circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "            if circularity > threshold:\n",
    "                # Add the object to the mask\n",
    "                mask[labeled_image == prop.label] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def remove_skinny_objects(binary_image: np.ndarray, aspect_ratio_thresh=3.0, eccentricity_thresh=0.95) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Removes long, skinny objects from a binary mask based on aspect ratio and eccentricity.\n",
    "    \n",
    "    Parameters:\n",
    "        binary_image (np.ndarray): Binary image with objects to filter.\n",
    "        aspect_ratio_thresh (float): Max allowed aspect ratio (e.g. 3.0).\n",
    "        eccentricity_thresh (float): Max allowed eccentricity (e.g. 0.95).\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Binary mask with skinny/elongated objects removed.\n",
    "    \"\"\"\n",
    "    labeled = label(binary_image)\n",
    "    output_mask = np.zeros_like(binary_image, dtype=np.uint8)\n",
    "\n",
    "    for region in regionprops(labeled):\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        height = maxr - minr\n",
    "        width = maxc - minc\n",
    "        aspect_ratio = max(width / height, height / width)\n",
    "\n",
    "        if aspect_ratio <= aspect_ratio_thresh and region.eccentricity <= eccentricity_thresh:\n",
    "            output_mask[labeled == region.label] = 1\n",
    "\n",
    "    return output_mask\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"Normalize image to range [0, 1] with small epsilon to avoid division by zero.\"\"\"\n",
    "    image = image.astype(np.float32)\n",
    "    return (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
    "\n",
    "\n",
    "def segment_cells(green_channel, min_diameter=150, max_diameter=800, step=25):\n",
    "    \"\"\"\n",
    "    Segment whole cells in the green channel using Cellpose.\n",
    "    - Suppresses very bright regions to reduce inclusion impact.\n",
    "    - Applies Gaussian blur for smoother input.\n",
    "    - Increases diameter until cells are found.\n",
    "    \"\"\"\n",
    "    green_channel = normalize_image(green_channel)\n",
    "    percentile_99 = np.percentile(green_channel, 99)\n",
    "    green_channel[green_channel > percentile_99] = percentile_99\n",
    "    smoothed = gaussian(green_channel, sigma=5)\n",
    "    smoothed = normalize_image(smoothed)\n",
    "\n",
    "    for diameter in range(min_diameter, max_diameter, step):\n",
    "        masks, flows, styles, _ = model.eval(smoothed, diameter=diameter, channels=[0, 0])\n",
    "        if np.any(masks):\n",
    "            return label(masks)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_inclusions(green_channel, mask, threshold):\n",
    "    \"\"\"\n",
    "    Extract bright inclusions from a masked cell region.\n",
    "    - Normalizes masked region.\n",
    "    - Applies threshold based on mean + std * threshold.\n",
    "    \"\"\"\n",
    "    #masked = green_channel * mask\n",
    "    #norm = normalize_image(masked)\n",
    "    #thresh_val = np.mean(norm) + threshold * np.std(norm)\n",
    "    #inclusion_mask = norm > thresh_val\n",
    "    #inclusion_mask = remove_small_objects(inclusion_mask, min_size=10)\n",
    "    applied_masked = gaussian(green_channel) * mask\n",
    "\n",
    "    norm = normalize_image(applied_masked)\n",
    "    thresh_val = np.mean(norm) + threshold * np.std(norm)\n",
    "    inclusion_mask = norm > thresh_val\n",
    "    inclusion_mask = remove_small_objects(inclusion_mask, min_size=MIN_INCLUSION_SIZE)\n",
    "    inclusion_mask = remove_skinny_objects(inclusion_mask, aspect_ratio_thresh=3.0, eccentricity_thresh=0.95)\n",
    "    return inclusion_mask\n",
    "\n",
    "def generate_inclusions(green_channel, mask, display_graph=False):\n",
    "    \"\"\"\n",
    "    Extract potential inclusions inside a cell.\n",
    "    - Blurs and masks the cell region.\n",
    "    - Computes intensity statistics for thresholding.\n",
    "    - Applies different threshold strategies depending on intensity distribution.\n",
    "    - Removes objects that are too small or too large to be inclusions.\n",
    "    - Optionally shows histogram for debugging.\n",
    "    \"\"\"\n",
    "    green_channel = normalize_image(green_channel)\n",
    "    applied_mask_blurred = gaussian(green_channel, sigma=1) * mask\n",
    "    applied_mask_eliminate_background = applied_mask_blurred[applied_mask_blurred > 0]\n",
    "\n",
    "\n",
    "    # Normalize the signal within the masked region\n",
    "    applied_mask_eliminate_background = normalize_image(applied_mask_eliminate_background)\n",
    "\n",
    "\n",
    "    # Compute descriptive statistics for intensity distribution\n",
    "    q3 = np.percentile(applied_mask_eliminate_background, 75)\n",
    "    hist, bin_edges = np.histogram(applied_mask_eliminate_background, bins='fd')\n",
    "    applied_mask = green_channel * mask\n",
    "\n",
    "\n",
    "    # Decide on thresholding strategy based on upper quartile\n",
    "    if q3 < 0.4 and len(bin_edges) > 20:\n",
    "        threshold = max(threshold_otsu(applied_mask), 0.4)\n",
    "    elif q3 >= 0.9:\n",
    "        threshold = 1  # very high, to exclude everything\n",
    "    else:\n",
    "        threshold = 0.999  # conservatively high\n",
    "\n",
    "\n",
    "    # Apply threshold and size-based filters\n",
    "    inclusions = applied_mask > threshold\n",
    "    inclusions = remove_small_objects(inclusions, min_size=MIN_INCLUSION_SIZE)\n",
    "    inclusions = inclusions ^ remove_small_objects(inclusions, min_size=MAX_INCLUSION_SIZE)\n",
    "\n",
    "\n",
    "    # Optional histogram display\n",
    "    if display_graph:\n",
    "        print(\"Threshold: \", threshold)\n",
    "        print(\"Bin count\", len(bin_edges))\n",
    "        plt.hist(applied_mask_eliminate_background, bins='fd')\n",
    "        plt.axvline(q3, color='purple', linestyle='dashed', linewidth=2, label=f'Q3: {q3:.2f}')\n",
    "        plt.legend()\n",
    "        plt.title(\"Intensity histogram\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return inclusions\n",
    "\n",
    "def generate_inclusion_image(green_channel, labeled_cells, threshold):\n",
    "    \"\"\"\n",
    "    Generate a binary image with all inclusions from all cells.\n",
    "    - Loops through each segmented cell.\n",
    "    - Extracts inclusions from each cell region.\n",
    "    - Combines all into one final binary image.\n",
    "    \"\"\"\n",
    "    inclusion_image = np.zeros_like(green_channel)\n",
    "\n",
    "    for i, cell in enumerate(regionprops(labeled_cells)):\n",
    "        if cell.area < 100:\n",
    "            continue\n",
    "        mask = labeled_cells == cell.label\n",
    "        #inclusions = extract_inclusions(green_channel, mask, threshold)\n",
    "        inclusions = extract_inclusions(green_channel, mask, threshold)\n",
    "        inclusion_image += inclusions  # adds binary inclusion mask\n",
    "\n",
    "    return inclusion_image\n",
    "\n",
    "\n",
    "def compute_nearest_distances(mask_a, mask_b, labeled_cells):\n",
    "    distances = []\n",
    "    for cell in regionprops(labeled_cells):\n",
    "        mask_a_cell = mask_a == cell.label\n",
    "        mask_b_cell = mask_b == cell.label\n",
    "        \n",
    "        if not np.any(mask_a_cell) or not np.any(mask_b_cell):\n",
    "            continue\n",
    "\n",
    "        props_a = regionprops(label(mask_a_cell))\n",
    "\n",
    "        dist_map = distance_transform_edt(~mask_b_cell)\n",
    "\n",
    "        for prop in props_a:\n",
    "            coords = prop.coords\n",
    "            # Check overlap\n",
    "            if np.any(mask_b[tuple(coords.T)]):\n",
    "                distances.append(0.0)\n",
    "            else:\n",
    "                # Measure minimum distance from any pixel of object A to mask B\n",
    "                dists = dist_map[tuple(coords.T)]\n",
    "                distances.append(np.min(dists))\n",
    "    \n",
    "    return np.array(distances)\n",
    "\n",
    "def calculate_densities(inclusion_image, cell, red_channel_thresholded):\n",
    "    mask = cell > 0\n",
    "    # dilate inclusion_image\n",
    "    dilated_inclusion_image = binary_dilation(inclusion_image, disk(RADIUS))\n",
    "    dilated_inclusion_image = dilated_inclusion_image * mask\n",
    "    dilated_inclusion_image_donut = dilated_inclusion_image ^ inclusion_image\n",
    "    overlap_with_inclusions = red_channel_thresholded * dilated_inclusion_image_donut\n",
    "    density_around_inclusions = np.sum(overlap_with_inclusions) / np.sum(dilated_inclusion_image_donut)\n",
    "\n",
    "    #display_image(inclusion_image, \"inclusion_image\", \"mask\")\n",
    "    #display_image(binary_dilation(inclusion_image, disk(RADIUS)), \"dilated_inclusion_image\", \"mask\")\n",
    "    #display_image(mask, \"mask\", \"mask\")\n",
    "    #display_image(dilated_inclusion_image, \"dilated_inclusion_image\", \"mask\")\n",
    "    #display_image(dilated_inclusion_image_donut, \"dilated_inclusion_image_donut\", \"mask\")\n",
    "\n",
    "\n",
    "    cell_without_dilated_inclusions = mask ^ dilated_inclusion_image\n",
    "    overlap_with_rest_of_the_cells = red_channel_thresholded * cell_without_dilated_inclusions\n",
    "    density_around_rest_of_the_cells = np.sum(overlap_with_rest_of_the_cells) / np.sum(cell_without_dilated_inclusions)\n",
    "    #display_image(cell_without_dilated_inclusions, \"cell_without_dilated_inclusions\", \"mask\")\n",
    "    #display_image(overlap_with_rest_of_the_cells, \"overlap_with_rest_of_the_cells\", \"mask\")\n",
    "    \n",
    "\n",
    "    return density_around_inclusions, density_around_rest_of_the_cells\n",
    "\n",
    "def plot_histogram(distances, path, inclusion_centered: bool):\n",
    "    \n",
    "    max_val = np.max(distances)\n",
    "    bins = np.concatenate(([-1, 0.01], np.arange(1, max_val + 2, 1)))\n",
    "    \n",
    "    # Plot histogram\n",
    "    plt.hist(distances, bins=bins, edgecolor='black')\n",
    "    \n",
    "    # Use automatic x-tick spacing with MaxNLocator\n",
    "    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True, prune='both'))\n",
    "    \n",
    "    plt.xlabel('Distance to Nearest Mitochondrion')\n",
    "    plt.ylabel('Frequency')\n",
    "    if inclusion_centered:\n",
    "        plt.title('Histogram with Bin for Zero Distances (Inclusion Centered)' + f\" ({path})\")\n",
    "    else:\n",
    "        plt.title('Histogram with Bin for Zero Distances (Red Centered)' + f\" ({path})\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def counting_number_of_inclusions_overlapping_with_red(inclusion_image, red_image):\n",
    "    count = 0\n",
    "    labeled_inclusions = label(inclusion_image)\n",
    "\n",
    "    for prop in regionprops(labeled_inclusions):\n",
    "        coords = prop.coords\n",
    "        if np.any(red_image[tuple(coords.T)]):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def red_objects_overlapping_with_green(red_mask, green_mask):\n",
    "    \"\"\"\n",
    "    Returns a binary mask containing only red objects that intersect with green mask.\n",
    "    \n",
    "    Parameters:\n",
    "    - red_mask: binary mask of red objects (0s and 1s)\n",
    "    - green_mask: binary mask of green objects (0s and 1s)\n",
    "    \n",
    "    Returns:\n",
    "    - output_mask: binary mask with only overlapping red objects (same shape as input)\n",
    "    \"\"\"\n",
    "    labeled_red = label(red_mask)\n",
    "    output_mask = np.zeros_like(red_mask, dtype=np.uint8)\n",
    "    \n",
    "    for prop in regionprops(labeled_red):\n",
    "        coords = prop.coords\n",
    "        if np.any(green_mask[tuple(coords.T)]):\n",
    "            output_mask[tuple(coords.T)] = 1\n",
    "    \n",
    "    return output_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_dox_analysis(red: np.ndarray, green:np.ndarray, path:str) -> pd.DataFrame:\n",
    "    data = []\n",
    "    df_cell_summary = pd.DataFrame()\n",
    "\n",
    "    labeled_cells = segment_cells(green)\n",
    "    if labeled_cells is None:\n",
    "        print(f\"No cells found in {path}. Skipping analysis.\")\n",
    "        return pd.DataFrame()\n",
    "    #display_image(labeled_cells, path, \"Labeled Cells\")\n",
    "    #green_thresholded = generate_inclusion_image(green, labeled_cells, 4)\n",
    "\n",
    "    red_threshold_value = 11000\n",
    "    green_threshold_value = 2000 \n",
    "    #while (green > green_threshold_value).any():\n",
    "    #    green_threshold_value += 1000\n",
    "    #while (red > red_threshold_value).any():\n",
    "    #    red_threshold_value += 1000     \n",
    "#\n",
    "    #print(f\"Red threshold value: {red_threshold_value}, Green threshold value: {green_threshold_value} {path}\")\n",
    "\n",
    "    threshold_red_otsu_value = threshold_otsu(red)\n",
    "    if (False):\n",
    "        print(\"bleedthrough detected, using Otsu's threshold value\")\n",
    "        mitochondria_thresholded = red > red_threshold_value\n",
    "        mitochondria_thresholded = remove_small_objects_only(mitochondria_thresholded, min_size=10)\n",
    "    else:\n",
    "        contrast_adjusted_red_normalized = (red - red.min()) / (red.max() - red.min())\n",
    "        threshold_value_mitochondria = np.mean(contrast_adjusted_red_normalized) + (np.std(contrast_adjusted_red_normalized) * 4) #1.75 works well\n",
    "        mitochondria_thresholded = contrast_adjusted_red_normalized > threshold_value_mitochondria\n",
    "        mitochondria_thresholded = remove_small_objects_only(mitochondria_thresholded, min_size=10)\n",
    "\n",
    "    threshold_green_otsu_value = threshold_otsu(green)\n",
    "    if (False):\n",
    "        print(\"bleedthrough detected, using Otsu's threshold value\")\n",
    "        green_thresholded = green > green_threshold_value\n",
    "        green_thresholded = remove_small_objects_only(green_thresholded, min_size=10)\n",
    "    else:\n",
    "        if re.search(r'LLOMe', path):\n",
    "            green_thresholded = generate_inclusion_image(green, labeled_cells, 6)\n",
    "        else:\n",
    "            green_thresholded = generate_inclusion_image(green, labeled_cells, 7)\n",
    "\n",
    "\n",
    "    #display_image(mitochondria_thresholded, path, \"Red Thresholded\")\n",
    "    #display_image(green_thresholded, path, \"Inclusions\")\n",
    "    \n",
    "\n",
    "    distances_inclusion = compute_nearest_distances(green_thresholded, mitochondria_thresholded, labeled_cells)\n",
    "    distances_red = compute_nearest_distances(mitochondria_thresholded, green_thresholded, labeled_cells)\n",
    "\n",
    "    #plot_histogram(distances_inclusion, path, inclusion_centered=True)\n",
    "    #plot_histogram(distances_red, path, inclusion_centered=False)  \n",
    "\n",
    "    cell_count = 0\n",
    "\n",
    "    for cell in regionprops(label(labeled_cells)):\n",
    "        cell_count += 1\n",
    "        mask = labeled_cells == cell.label\n",
    "        inclusions_in_cell = mask * green_thresholded\n",
    "        red_in_cell = mask * mitochondria_thresholded\n",
    "\n",
    "        #display_image(red_in_cell, path, f\"Red in Cell {cell.label}\")\n",
    "        #display_image(inclusions_in_cell, path, f\"Inclusions in Cell {cell.label}\")\n",
    "\n",
    "        red_surface_area = calculate_surface_area(label(red_in_cell))\n",
    "        green_surface_area = calculate_surface_area(label(inclusions_in_cell))\n",
    "        overlap_surface_area = calculate_surface_area(label(red_in_cell) & label(inclusions_in_cell))\n",
    "\n",
    "\n",
    "        if not np.any(inclusions_in_cell) or not np.any(red_in_cell):\n",
    "            density_around_inclusions = 0\n",
    "            density_around_rest_of_the_cells = 0\n",
    "            density_around_red = 0\n",
    "            density_around_rest_of_the_cells_referrring_to_red = 0\n",
    "\n",
    "        else:\n",
    "            density_around_red, density_around_rest_of_the_cells_referrring_to_red = calculate_densities(red_in_cell, mask, inclusions_in_cell)\n",
    "            density_around_inclusions, density_around_rest_of_the_cells = calculate_densities(inclusions_in_cell, mask, red_in_cell)          \n",
    "\n",
    "\n",
    "        #display_image(inclusions_in_cell, path, f\"Inclusions in Cell {cell.label}\")\n",
    "        #display_image(red_in_cell, path, f\"Red in Cell {cell.label}\")\n",
    "        #display_image(mask, path, f\"Mask for Cell {cell.label}\")\n",
    "\n",
    "        green_overlap_red_num = counting_number_of_inclusions_overlapping_with_red(inclusions_in_cell, red_in_cell)\n",
    "        green_total_num = count(inclusions_in_cell)\n",
    "        red_total_num = count(red_in_cell)\n",
    "\n",
    "        data.append({\n",
    "            'Image Path': path,\n",
    "            'Cell Number': cell_count,\n",
    "            'Red Surface Area': red_surface_area,\n",
    "            'Green Surface Area': green_surface_area,\n",
    "            'Overlap Surface Area': overlap_surface_area,\n",
    "            'Overlap / Red Surface Area': overlap_surface_area / red_surface_area if red_surface_area > 0 else 0,\n",
    "            'Overlap / Green Surface Area': overlap_surface_area / green_surface_area if green_surface_area > 0 else 0,\n",
    "            'Density Around Galectin': density_around_inclusions,\n",
    "            'Density Around Rest of Cells (refering to galectin)': density_around_rest_of_the_cells,\n",
    "            'Density Around Red': density_around_red,\n",
    "            'Density Around Rest of Cells (refering to red)': density_around_rest_of_the_cells_referrring_to_red,\n",
    "            'Green Overlap with Red Num': green_overlap_red_num,\n",
    "            'Green Total Num': green_total_num,\n",
    "            'Red Total Num': red_total_num,\n",
    "            'overlap num/red total num': green_overlap_red_num / red_total_num if red_total_num > 0 else 0,\n",
    "        })\n",
    "        \n",
    "\n",
    "    df_cell_summary = pd.DataFrame(data)\n",
    "    return df_cell_summary\n",
    "\n",
    "\n",
    "\n",
    "def dox_analysis(red: np.ndarray, green:np.ndarray, path:str) -> pd.DataFrame:\n",
    "    data = []\n",
    "    df_cell_summary = pd.DataFrame()\n",
    "\n",
    "    data_inclusions = []\n",
    "    df_cell_inclusions_summary = pd.DataFrame()\n",
    "\n",
    "    red_threshold_value = 7000\n",
    "    green_threshold_value = 8000 \n",
    "    #while (green > green_threshold_value).any():\n",
    "    #    green_threshold_value += 1000\n",
    "    #while (red > red_threshold_value).any():\n",
    "    #    red_threshold_value += 1000     \n",
    "#\n",
    "    #print(f\"Red threshold value: {red_threshold_value}, Green threshold value: {green_threshold_value} {path}\")\n",
    "\n",
    "    threshold_otsu_value = threshold_otsu(red)\n",
    "    threshold_green_otsu_value = threshold_otsu(green)\n",
    "\n",
    "    labeled_cells = segment_cells(green)\n",
    "\n",
    "    \n",
    "    if threshold_otsu_value < red_threshold_value:\n",
    "        print(\"bleedthrough detected, using Otsu's threshold value\")\n",
    "        mitochondria_thresholded = red > red_threshold_value\n",
    "        mitochondria_thresholded = remove_small_objects_only(mitochondria_thresholded, min_size=10)\n",
    "    else:\n",
    "        if re.search(r'LLOMe', path):\n",
    "            contrast_adjusted_red_normalized = (red - red.min()) / (red.max() - red.min())\n",
    "            threshold_value_mitochondria = np.mean(contrast_adjusted_red_normalized) + (np.std(contrast_adjusted_red_normalized) * 3.5)\n",
    "            mitochondria_thresholded = contrast_adjusted_red_normalized > threshold_value_mitochondria\n",
    "            mitochondria_thresholded = remove_small_objects_only(mitochondria_thresholded, min_size=10)\n",
    "        else:\n",
    "            contrast_adjusted_red_normalized = (red - red.min()) / (red.max() - red.min())\n",
    "            threshold_value_mitochondria = np.mean(contrast_adjusted_red_normalized) + (np.std(contrast_adjusted_red_normalized) * 4.5)\n",
    "            mitochondria_thresholded = contrast_adjusted_red_normalized > threshold_value_mitochondria\n",
    "            mitochondria_thresholded = remove_small_objects_only(mitochondria_thresholded, min_size=10)\n",
    "\n",
    "    if re.search(r'LLOMe', path):\n",
    "        green_thresholded = generate_inclusion_image(green, labeled_cells, 3.5)\n",
    "    else:\n",
    "        green_thresholded = generate_inclusion_image(green, labeled_cells, 4)\n",
    "\n",
    "\n",
    "    #display_image(green > green_threshold_value, path, \"Red Thresholded\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    display_image(mitochondria_thresholded, path, \"Red Thresholded\")\n",
    "    display_image(green_thresholded, path, \"Inclusions\")\n",
    "    \n",
    "    distances_inclusion = compute_nearest_distances(green_thresholded, mitochondria_thresholded, labeled_cells)\n",
    "    distances_red = compute_nearest_distances(mitochondria_thresholded, green_thresholded, labeled_cells)\n",
    "\n",
    "    #plot_histogram(distances_inclusion, path, inclusion_centered=True)\n",
    "    #plot_histogram(distances_red, path, inclusion_centered=False)  \n",
    "\n",
    "    cell_count = 0\n",
    "    for cell in regionprops(label(labeled_cells)):\n",
    "        cell_count += 1\n",
    "        mask = labeled_cells == cell.label\n",
    "        inclusions_in_cell = mask * green_thresholded\n",
    "        red_in_cell = mask * mitochondria_thresholded\n",
    "\n",
    "        labeled_inclusions = label(inclusions_in_cell)\n",
    "        inclusion_num = 0\n",
    "        for inclusion in regionprops(labeled_inclusions):\n",
    "            inclusion_label = inclusion.label\n",
    "            inclusion_size = inclusion.area\n",
    "            inclusion_num += 1\n",
    "\n",
    "            data_inclusions.append({\n",
    "                'Image Path': path,\n",
    "                'Cell': cell_count,\n",
    "                'Inclusion': inclusion_num,\n",
    "                'Size': inclusion_size\n",
    "            })\n",
    "\n",
    "\n",
    "        red_overlapping = red_objects_overlapping_with_green(red_in_cell, inclusions_in_cell)\n",
    "\n",
    "\n",
    "        red_og_overlapping = red * red_overlapping\n",
    "\n",
    "        average_red_mfi = np.mean(red_og_overlapping) if np.any(red_og_overlapping) else 0.0\n",
    "\n",
    "        red_overlapping_strict = red_in_cell * inclusions_in_cell\n",
    "\n",
    "        average_red_strict_mfi = np.mean(red_overlapping_strict) if np.any(red_overlapping_strict) else 0.0\n",
    "        \n",
    "        #display_image(inclusions_in_cell, path, f\"Inclusions in Cell {cell.label}\")\n",
    "        #display_image(red_in_cell, path, f\"Red in Cell {cell.label}\")\n",
    "        #display_image(red_overlapping, path, f\"Red Overlapping with Green in Cell {cell.label}\")\n",
    "        #display_image(red_og_overlapping, path, f\"Red in Cell {cell.label}\")\n",
    "        #display_image(red_overlapping_strict, path, f\"Red Overlapping Strict in Cell {cell.label}\")\n",
    "\n",
    "        red_surface_area = calculate_surface_area(label(red_in_cell))\n",
    "        green_surface_area = calculate_surface_area(label(inclusions_in_cell))\n",
    "        overlap_surface_area = calculate_surface_area(label(red_in_cell) & label(inclusions_in_cell))\n",
    "\n",
    "        if not np.any(inclusions_in_cell) or not np.any(red_in_cell):\n",
    "            density_around_inclusions = 0\n",
    "            density_around_rest_of_the_cells = 0\n",
    "        else:\n",
    "            density_around_inclusions, density_around_rest_of_the_cells = calculate_densities(inclusions_in_cell, mask, red_in_cell)\n",
    "\n",
    "        green_overlap_red_num = counting_number_of_inclusions_overlapping_with_red(inclusions_in_cell, red_in_cell)\n",
    "        green_total_num = count(inclusions_in_cell)\n",
    "        red_total_num = count(red_in_cell)\n",
    "\n",
    "        data.append({\n",
    "            'Image Path': path,\n",
    "            'Cell Number': cell_count,\n",
    "            'Red Surface Area': red_surface_area,\n",
    "            'Green Surface Area': green_surface_area,\n",
    "            'Overlap Surface Area': overlap_surface_area,\n",
    "            'Overlap / Red Surface Area': overlap_surface_area / red_surface_area if red_surface_area > 0 else 0,\n",
    "            'Overlap / Green Surface Area': overlap_surface_area / green_surface_area if green_surface_area > 0 else 0,\n",
    "            'Density Around Inclusions': density_around_inclusions,\n",
    "            'Density Around Rest of Cells': density_around_rest_of_the_cells,\n",
    "            'Green Overlap with Red Num': green_overlap_red_num,\n",
    "            'Green Total Num': green_total_num,\n",
    "            'Red Total Num': red_total_num,\n",
    "            'Average Red Entire Object MFI': average_red_mfi,\n",
    "            'Average Red Strict MFI': average_red_strict_mfi\n",
    "        })\n",
    "\n",
    "    df_cell_summary = pd.DataFrame(data)\n",
    "    df_cell_inclusions_summary = pd.DataFrame(data_inclusions)\n",
    "\n",
    "    return df_cell_summary, df_cell_inclusions_summary\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     39\u001b[0m     image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m53025/3K\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 40\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 28\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(image_folder)\u001b[0m\n\u001b[0;32m     25\u001b[0m output_df_summary_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m53025_3K_nodox.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m df_summary_combined_df\u001b[38;5;241m.\u001b[39mto_excel(output_df_summary_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 28\u001b[0m df_inclusion_summary_combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_dox_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m output_df_inclusion_summary_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m53025_WT_dox.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m df_inclusion_summary_combined_df\u001b[38;5;241m.\u001b[39mto_excel(output_df_inclusion_summary_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\sj1205\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\sj1205\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\Users\\sj1205\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "def main(image_folder):\n",
    "    images_to_analyze = extract_image_paths(image_folder)\n",
    "    output_dir = os.getcwd()\n",
    "\n",
    "    df_dox_summary = []\n",
    "    df_no_dox_summary = []\n",
    "    df_inclusion_summary = []\n",
    "    for path in images_to_analyze:\n",
    "        image = read_image(path)\n",
    "        image_squeezed = np.squeeze(image) \n",
    "\n",
    "        red, green = extract_channels(image_squeezed)\n",
    "        if \"nodox\" in path:\n",
    "            df_cell_summary_no_dox = no_dox_analysis(red, green, path)\n",
    "            df_no_dox_summary.append(df_cell_summary_no_dox)\n",
    "            #continue\n",
    "\n",
    "        else: \n",
    "            #df_cell_summary, df_cell_inclusions_summary = dox_analysis(red, green, path)\n",
    "            #df_dox_summary.append(df_cell_summary)\n",
    "            #df_inclusion_summary.append(df_cell_inclusions_summary)\n",
    "            continue\n",
    "\n",
    "    df_summary_combined_df = pd.concat(df_no_dox_summary, ignore_index=True)\n",
    "    output_df_summary_path = os.path.join(output_dir, '53025_3K_nodox.xlsx')\n",
    "    df_summary_combined_df.to_excel(output_df_summary_path, index=False)\n",
    "\n",
    "    df_inclusion_summary_combined_df = pd.concat(df_dox_summary, ignore_index=True)\n",
    "    output_df_inclusion_summary_path = os.path.join(output_dir, '53025_WT_dox.xlsx')\n",
    "    df_inclusion_summary_combined_df.to_excel(output_df_inclusion_summary_path, index=False)\n",
    "\n",
    "    df_inclusion_summary_combined_df = pd.concat(df_inclusion_summary, ignore_index=True)\n",
    "    output_df_inclusion_summary_path = os.path.join(output_dir, '53025_WT_dox_inclusions.xlsx')\n",
    "    df_inclusion_summary_combined_df.to_excel(output_df_inclusion_summary_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_folder = '53025/3K'\n",
    "    main(image_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
