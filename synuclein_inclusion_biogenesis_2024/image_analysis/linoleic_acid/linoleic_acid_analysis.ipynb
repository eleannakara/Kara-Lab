{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0322d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import gaussian, threshold_otsu, threshold_multiotsu, sobel\n",
    "from skimage.morphology import remove_small_objects, disk, binary_closing\n",
    "from scipy.ndimage import zoom, binary_dilation, binary_erosion, distance_transform_edt\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import io, exposure, color\n",
    "from skimage import measure, morphology\n",
    "from skimage import exposure\n",
    "from czifile import imread\n",
    "import cv2\n",
    "import re\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from cellpose import models, plot \n",
    "#model = models.Cellpose(gpu=False, model_type='cyto3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaddb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_INCLUSION_SIZE = 5\n",
    "MAX_INCLUSION_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6a6df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, path, type):\n",
    "    \"\"\"Display the image.\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{path} {type}\")\n",
    "    plt.show()\n",
    "\n",
    "def extract_image_paths(folder):\n",
    "    \"\"\"Extract all image file paths from the specified folder.\"\"\"\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"Read the LSM image from the specified path.\"\"\"\n",
    "    return imread(image_path)\n",
    "\n",
    "def count(mask): \n",
    "    \"\"\"Count the number of unique labels in the mask.\"\"\"\n",
    "    return len(np.unique(label(mask))) - 1  # Exclude background label (0)\n",
    "\n",
    "def extract_channels(image: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Extract green and red channels from the squeezed image (shape: [Z, C, H, W]).\"\"\" \n",
    "    return image[0], image[1]\n",
    "\n",
    "def preprocess_green_channel(green_channel):\n",
    "    \"\"\"\n",
    "    Preprocess the green fluorescence channel for better segmentation and inclusion detection.\n",
    "    - Applies Gaussian blur to reduce noise.\n",
    "    - Enhances contrast using sigmoid adjustment.\n",
    "    - Normalizes intensities to [0, 1] for consistent processing.\n",
    "    \"\"\"\n",
    "    confocal_img = gaussian(green_channel, sigma=2)\n",
    "    confocal_img = exposure.adjust_sigmoid(green_channel, cutoff=0.25)\n",
    "    confocal_img = normalize_image(confocal_img)\n",
    "    return confocal_img\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize the image to the range [0, 1].\n",
    "    This is useful for consistent processing across different images.\n",
    "    \"\"\"\n",
    "    return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "\n",
    "def calculate_surface_area(labeled_image: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the total surface area for labeled regions.\"\"\"\n",
    "    props = regionprops(labeled_image)\n",
    "    return sum(prop.area for prop in props)\n",
    "\n",
    "def high_circularity_mask(labeled_image: np.ndarray, threshold: float = 0.7) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return a binary mask with only the regions that have a circularity index higher than the threshold.\n",
    "    \n",
    "    Parameters:\n",
    "        labeled_image (np.ndarray): Labeled image where each object has a unique label.\n",
    "        threshold (float): Minimum circularity index to keep the object.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Binary mask with only high-circularity objects.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(labeled_image, dtype=np.uint8)\n",
    "    props = regionprops(labeled_image)\n",
    "\n",
    "    for prop in props:\n",
    "        perimeter = prop.perimeter\n",
    "        area = prop.area\n",
    "        if perimeter > 0:\n",
    "            circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "            if circularity > threshold:\n",
    "                # Add the object to the mask\n",
    "                mask[labeled_image == prop.label] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def segment_cells(green_channel):\n",
    "    \"\"\"\n",
    "    Segment whole cells in the green channel using Cellpose.\n",
    "    - Normalizes image intensity.\n",
    "    - Suppresses bright spots (e.g., inclusions) to better detect cell boundaries.\n",
    "    - Applies Gaussian blur for smoother segmentation input.\n",
    "    - Gradually increases segmentation diameter until at least one cell is detected.\n",
    "    \"\"\"\n",
    "    green_channel = normalize_image(green_channel)\n",
    "    percentile_99 = np.percentile(green_channel, 99)\n",
    "    \n",
    "    # Suppress very bright pixels (inclusions)\n",
    "    green_channel_remove_inclusions = np.where(green_channel < percentile_99, green_channel, percentile_99)\n",
    "    green_channel_remove_inclusions = gaussian(green_channel_remove_inclusions, sigma=5)\n",
    "\n",
    "    # Normalize again after processing\n",
    "    green_channel_remove_inclusions = normalize_image(green_channel_remove_inclusions)\n",
    "\n",
    "    # Try different diameters until cells are detected\n",
    "    diameter = 150\n",
    "    while diameter < 500:\n",
    "        masks, flows, styles, diams = model.eval(green_channel_remove_inclusions, diameter=diameter, channels=[0, 0])\n",
    "        labeled_cells = label(masks)\n",
    "        if np.max(labeled_cells) > 0:\n",
    "            return labeled_cells\n",
    "        diameter += 25\n",
    "\n",
    "    # No cells found\n",
    "\n",
    "def extract_inclusions(green_channel, mask, display_graph=False):\n",
    "    \"\"\"\n",
    "    Extract potential inclusions inside a cell.\n",
    "    - Blurs and masks the cell region.\n",
    "    - Computes intensity statistics for thresholding.\n",
    "    - Applies different threshold strategies depending on intensity distribution.\n",
    "    - Removes objects that are too small or too large to be inclusions.\n",
    "    - Optionally shows histogram for debugging.\n",
    "    \"\"\"\n",
    "    applied_mask_blurred = gaussian(green_channel, sigma=1) * mask\n",
    "    applied_mask_eliminate_background = applied_mask_blurred[applied_mask_blurred > 0]\n",
    "\n",
    "\n",
    "    # Normalize the signal within the masked region\n",
    "    applied_mask_eliminate_background = normalize_image(applied_mask_eliminate_background)\n",
    "\n",
    "\n",
    "    # Compute descriptive statistics for intensity distribution\n",
    "    q3 = np.percentile(applied_mask_eliminate_background, 75)\n",
    "    hist, bin_edges = np.histogram(applied_mask_eliminate_background, bins='fd')\n",
    "    applied_mask = normalize_image(green_channel) * mask\n",
    "\n",
    "\n",
    "    # Decide on thresholding strategy based on upper quartile\n",
    "    if q3 < 0.4 and len(bin_edges) > 20:\n",
    "        threshold = max(threshold_otsu(applied_mask), 0.5)\n",
    "    elif q3 >= 0.9:\n",
    "        threshold = 1  # very high, to exclude everything\n",
    "    else:\n",
    "        threshold = 0.999  # conservatively high\n",
    "\n",
    "\n",
    "    # Apply threshold and size-based filters\n",
    "    #threshold = max(threshold_otsu(applied_mask), 0.38)\n",
    "    inclusions = applied_mask > threshold\n",
    "    inclusions = remove_small_objects(inclusions, min_size=MIN_INCLUSION_SIZE)\n",
    "    #inclusions = inclusions ^ remove_small_objects(inclusions, min_size=MAX_INCLUSION_SIZE)\n",
    "\n",
    "\n",
    "    # Optional histogram display\n",
    "    if display_graph:\n",
    "        print(\"Threshold: \", threshold)\n",
    "        print(\"Bin count\", len(bin_edges))\n",
    "        plt.hist(applied_mask_eliminate_background, bins='fd')\n",
    "        plt.axvline(q3, color='purple', linestyle='dashed', linewidth=2, label=f'Q3: {q3:.2f}')\n",
    "        plt.legend()\n",
    "        plt.title(\"Intensity histogram\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return inclusions\n",
    "\n",
    "def generate_inclusion_image(green_channel, labeled_cells):\n",
    "    \"\"\"\n",
    "    Generate a binary image with all inclusions from all cells.\n",
    "    - Loops through each segmented cell.\n",
    "    - Extracts inclusions from each cell region.\n",
    "    - Combines all into one final binary image.\n",
    "    \"\"\"\n",
    "    inclusion_image = np.zeros_like(green_channel)\n",
    "\n",
    "    for i, cell in enumerate(regionprops(labeled_cells)):\n",
    "        if cell.area < 100:\n",
    "            continue\n",
    "        mask = labeled_cells == cell.label\n",
    "        inclusions = extract_inclusions(green_channel, mask)\n",
    "        inclusion_image += inclusions  # adds binary inclusion mask\n",
    "\n",
    "    return inclusion_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d0ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(red: np.ndarray, green:np.ndarray, path:str) -> pd.DataFrame:\n",
    "    data = []\n",
    "    df_cell_summary = pd.DataFrame()\n",
    "\n",
    "    print(\"Starting analysis...\")\n",
    "\n",
    "    # Preprocess the green channel\n",
    "    green = preprocess_green_channel(green)\n",
    "\n",
    "    \n",
    "    display_image(green, path, \"Green Channel\")\n",
    "\n",
    "    return green\n",
    "\n",
    "    #labeled_cells = segment_cells(green)\n",
    "\n",
    "    #display_image(labeled_cells, path, \"Labeled Cells\")\n",
    "\n",
    "    #inclusion_image = generate_inclusion_image(green, labeled_cells)\n",
    "    #display_image(inclusion_image, path, \"Inclusion Image\")\n",
    "\n",
    "    # Extract inclusions from the green channel\n",
    "    #inclusions = extract_inclusions(green, inclusion_image, display_graph=True)\n",
    "    #display_image(inclusions, path, \"Inclusions\")\n",
    "\n",
    "    #for i, cell in enumerate(regionprops(labeled_cells)):\n",
    "    #    if cell.area < 100:  # Skip tiny regions likely to be noise\n",
    "    #        continue\n",
    "#\n",
    "    #            # Create a mask for the current cell\n",
    "    #    mask = labeled_cells == cell.label\n",
    "#\n",
    "    #    original_cell = green * mask\n",
    "#\n",
    "    #    #display_image(original_cell, path, f\"Cell Mask {i+1}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ff3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(image_folder):\n",
    "    images_to_analyze = extract_image_paths(image_folder)\n",
    "    output_dir = os.getcwd()\n",
    "\n",
    "    for path in images_to_analyze:\n",
    "        image = read_image(path)\n",
    "        image_squeezed = np.squeeze(image) \n",
    "    \n",
    "        red, green = extract_channels(image_squeezed)\n",
    "    \n",
    "        # Create output folder for normalized images\n",
    "        normalized_output_dir = os.path.join(os.getcwd(), \"green_channel_images\")\n",
    "        os.makedirs(normalized_output_dir, exist_ok=True)\n",
    "    \n",
    "        # Build the output file name\n",
    "        base_name = os.path.splitext(os.path.basename(path))[0]\n",
    "        output_path = os.path.join(normalized_output_dir, f\"{base_name}_green.png\")\n",
    "    \n",
    "        # Normalize and save image\n",
    "        #if green.dtype != np.uint8:\n",
    "        #    green_uint8 = (green * 255).clip(0, 255).astype(np.uint8)\n",
    "        #else:\n",
    "        #    green_uint8 = green\n",
    "    \n",
    "        io.imsave(output_path, green)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_folder = '52925_images'\n",
    "    main(image_folder)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
