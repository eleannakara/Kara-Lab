{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0322d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import gaussian, threshold_otsu, threshold_multiotsu, sobel, threshold_sauvola\n",
    "from skimage.morphology import remove_small_objects, disk, binary_closing\n",
    "from scipy.ndimage import zoom, binary_dilation, binary_erosion, distance_transform_edt\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import io, exposure, color\n",
    "from skimage import measure, morphology\n",
    "from skimage import exposure\n",
    "from czifile import imread\n",
    "import cv2\n",
    "import re\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from cellpose import models, plot \n",
    "model = models.Cellpose(model_type='cyto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaddb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_INCLUSION_SIZE = 10\n",
    "MAX_INCLUSION_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6a6df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, path, type):\n",
    "    \"\"\"Display the image.\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{path} {type}\")\n",
    "    plt.show()\n",
    "\n",
    "def extract_image_paths(folder):\n",
    "    \"\"\"Extract all image file paths from the specified folder.\"\"\"\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"Read the LSM image from the specified path.\"\"\"\n",
    "    return imread(image_path)\n",
    "\n",
    "def count(mask): \n",
    "    \"\"\"Count the number of unique labels in the mask.\"\"\"\n",
    "    return len(np.unique(label(mask))) - 1  # Exclude background label (0)\n",
    "\n",
    "def extract_channels(image: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Extract green and red channels from the squeezed image (shape: [Z, C, H, W]).\"\"\" \n",
    "    return image[0], image[1]\n",
    "\n",
    "def preprocess_green_channel(green_channel):\n",
    "    \"\"\"\n",
    "    Preprocess the green fluorescence channel for better segmentation and inclusion detection.\n",
    "    - Applies Gaussian blur to reduce noise.\n",
    "    - Enhances contrast using sigmoid adjustment.\n",
    "    - Normalizes intensities to [0, 1] for consistent processing.\n",
    "    \"\"\"\n",
    "    confocal_img = gaussian(green_channel, sigma=2)\n",
    "    confocal_img = exposure.adjust_sigmoid(green_channel, cutoff=0.25)\n",
    "    confocal_img = normalize_image(confocal_img)\n",
    "    return confocal_img\n",
    "\n",
    "    return circular_mask, non_circular_mask\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize the image to the range [0, 1].\n",
    "    This is useful for consistent processing across different images.\n",
    "    \"\"\"\n",
    "    return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "\n",
    "def calculate_surface_area(labeled_image: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the total surface area for labeled regions.\"\"\"\n",
    "    props = regionprops(labeled_image)\n",
    "    return sum(prop.area for prop in props)\n",
    "\n",
    "\n",
    "def split_by_circularity(binary_mask: np.ndarray, threshold: float):\n",
    "    \"\"\"\n",
    "    Splits objects in a binary mask based on circularity.\n",
    "    \n",
    "    Parameters:\n",
    "        binary_mask (ndarray): Binary image with objects (1) and background (0).\n",
    "        threshold (float): Circularity threshold (0 to 1). Higher is more circular.\n",
    "        \n",
    "    Returns:\n",
    "        circular_mask (ndarray): Mask of objects above threshold.\n",
    "        non_circular_mask (ndarray): Mask of objects below or equal to threshold.\n",
    "    \"\"\"\n",
    "    labeled = label(binary_mask)\n",
    "    circular_mask = np.zeros_like(binary_mask, dtype=bool)\n",
    "    non_circular_mask = np.zeros_like(binary_mask, dtype=bool)\n",
    "\n",
    "    for region in regionprops(labeled):\n",
    "\n",
    "        perimeter = region.perimeter or 1  # Avoid divide-by-zero\n",
    "        circularity = 4 * np.pi * region.area / (perimeter ** 2)\n",
    "\n",
    "        if circularity > threshold:\n",
    "            circular_mask[labeled == region.label] = True\n",
    "        else:\n",
    "            non_circular_mask[labeled == region.label] = True\n",
    "\n",
    "    return circular_mask, non_circular_mask\n",
    "\n",
    "def segment_cells(green_channel):\n",
    "    \"\"\"\n",
    "    Segment whole cells in the green channel using Cellpose.\n",
    "    - Normalizes image intensity.\n",
    "    - Suppresses bright spots (e.g., inclusions) to better detect cell boundaries.\n",
    "    - Applies Gaussian blur for smoother segmentation input.\n",
    "    - Gradually increases segmentation diameter until at least one cell is detected.\n",
    "    \"\"\"\n",
    "    green_channel = normalize_image(green_channel)\n",
    "    percentile_99 = np.percentile(green_channel, 99)\n",
    "    \n",
    "    # Suppress very bright pixels (inclusions)\n",
    "    green_channel_remove_inclusions = np.where(green_channel < percentile_99, green_channel, percentile_99)\n",
    "    green_channel_remove_inclusions = gaussian(green_channel_remove_inclusions, sigma=5)\n",
    "\n",
    "    # Normalize again after processing\n",
    "    green_channel_remove_inclusions = normalize_image(green_channel_remove_inclusions)\n",
    "\n",
    "    # Try different diameters until cells are detected\n",
    "    diameter = 150\n",
    "    while diameter < 500:\n",
    "        masks, flows, styles, diams = model.eval(green_channel_remove_inclusions, diameter=diameter, channels=[0, 0])\n",
    "        labeled_cells = label(masks)\n",
    "        if np.max(labeled_cells) > 0:\n",
    "            return labeled_cells\n",
    "        diameter += 25\n",
    "\n",
    "    # No cells found\n",
    "    return None\n",
    "\n",
    "def extract_inclusions(green_channel, mask, display_graph=False):\n",
    "    \"\"\"\n",
    "    Extract potential inclusions inside a cell.\n",
    "    - Blurs and masks the cell region.\n",
    "    - Computes intensity statistics for thresholding.\n",
    "    - Applies different threshold strategies depending on intensity distribution.\n",
    "    - Removes objects that are too small or too large to be inclusions.\n",
    "    - Optionally shows histogram for debugging.\n",
    "    \"\"\"\n",
    "    applied_mask_blurred = gaussian(green_channel, sigma=1) * mask\n",
    "    applied_mask_eliminate_background = applied_mask_blurred[applied_mask_blurred > 0]\n",
    "\n",
    "    # Normalize the signal within the masked region\n",
    "    applied_mask_eliminate_background = normalize_image(applied_mask_eliminate_background)\n",
    "\n",
    "\n",
    "    # Compute descriptive statistics for intensity distribution\n",
    "    q3 = np.percentile(applied_mask_eliminate_background, 75)\n",
    "    hist, bin_edges = np.histogram(applied_mask_eliminate_background, bins='fd')\n",
    "    applied_mask = normalize_image(green_channel) * mask\n",
    "\n",
    "\n",
    "    # Decide on thresholding strategy based on upper quartile\n",
    "    if q3 < 0.4 and len(bin_edges) > 20:\n",
    "        #threshold = max(threshold_otsu(applied_mask), 0.5)\n",
    "        threshold = max(threshold_otsu(applied_mask), 0.5)\n",
    "    else:\n",
    "        threshold = 0.95\n",
    "\n",
    "    # Apply threshold and size-based filters\n",
    "    #threshold = max(threshold_otsu(applied_mask), 0.38)\n",
    "    inclusions = applied_mask > threshold\n",
    "    inclusions = remove_small_objects(inclusions, min_size=MIN_INCLUSION_SIZE)\n",
    "    #inclusions = inclusions ^ remove_small_objects(inclusions, min_size=MAX_INCLUSION_SIZE)\n",
    "\n",
    "\n",
    "    # Optional histogram display\n",
    "    if display_graph:\n",
    "        print(\"Threshold: \", threshold)\n",
    "        print(\"Bin count\", len(bin_edges))\n",
    "        plt.hist(applied_mask_eliminate_background, bins='fd')\n",
    "        plt.axvline(q3, color='purple', linestyle='dashed', linewidth=2, label=f'Q3: {q3:.2f}')\n",
    "        plt.legend()\n",
    "        plt.title(\"Intensity histogram\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return inclusions\n",
    "\n",
    "def generate_inclusion_image(green_channel, labeled_cells):\n",
    "    \"\"\"\n",
    "    Generate a binary image with all inclusions from all cells.\n",
    "    - Loops through each segmented cell.\n",
    "    - Extracts inclusions from each cell region.\n",
    "    - Combines all into one final binary image.\n",
    "    \"\"\"\n",
    "    inclusion_image = np.zeros_like(green_channel)\n",
    "\n",
    "    for i, cell in enumerate(regionprops(labeled_cells)):\n",
    "        if cell.area < 100:\n",
    "            continue\n",
    "        mask = labeled_cells == cell.label\n",
    "        inclusions = extract_inclusions(green_channel, mask)\n",
    "        inclusion_image += inclusions  # adds binary inclusion mask\n",
    "\n",
    "    return inclusion_image\n",
    "\n",
    "\n",
    "def filter_objects_by_overlap(source_mask, target_mask):\n",
    "    \"\"\"\n",
    "    Keeps objects in `source_mask` that overlap with `target_mask`.\n",
    "\n",
    "    Parameters:\n",
    "        source_mask (ndarray): Binary mask with objects to test (e.g. clustered mitochondria).\n",
    "        target_mask (ndarray): Binary mask defining inclusion region.\n",
    "\n",
    "    Returns:\n",
    "        filtered_mask (ndarray): Binary mask of source objects overlapping with target.\n",
    "    \"\"\"\n",
    "    labeled_source = label(source_mask)\n",
    "    filtered_mask = np.zeros_like(source_mask, dtype=bool)\n",
    "\n",
    "    for region in regionprops(labeled_source):\n",
    "        coords = tuple(region.coords.T)\n",
    "        if np.any(target_mask[coords]):\n",
    "            filtered_mask[coords] = True\n",
    "\n",
    "    return filtered_mask\n",
    "\n",
    "def find_swiss_cheese_inclusions(inclusion_image, red_channel_thresholded, verbose=False):\n",
    "    swiss_chess_inclusions = np.zeros_like(inclusion_image)\n",
    "    regular_inclusions = np.zeros_like(inclusion_image)\n",
    "    labeled_inclusions = label(inclusion_image)\n",
    "    for i, inclusion in enumerate(regionprops(labeled_inclusions)):\n",
    "        mask = labeled_inclusions == inclusion.label\n",
    "        overlap = mask * red_channel_thresholded\n",
    "        if np.sum(overlap) > 0:\n",
    "            swiss_chess_inclusions += mask\n",
    "        else:\n",
    "            regular_inclusions += mask\n",
    "    return swiss_chess_inclusions, regular_inclusions\n",
    "\n",
    "def seperate_single_LDS(inclusion_image, single_LDS_mask):\n",
    "    single_LDS_in_inclusions = np.zeros_like(single_LDS_mask)\n",
    "    single_LDS_in_cyto = np.zeros_like(single_LDS_mask)\n",
    "\n",
    "    labled_LDS = label(single_LDS_mask)\n",
    "    for i, region in enumerate(regionprops(labled_LDS)):\n",
    "        mask = labled_LDS == region.label\n",
    "        overlap = mask * inclusion_image\n",
    "        if np.sum(overlap) > 0:\n",
    "            single_LDS_in_inclusions += mask\n",
    "        else:\n",
    "            single_LDS_in_cyto += mask\n",
    "    return single_LDS_in_inclusions, single_LDS_in_cyto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d0ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(red: np.ndarray, green:np.ndarray, path:str) -> pd.DataFrame:\n",
    "    data = []\n",
    "    df_cell_summary = pd.DataFrame()\n",
    "\n",
    "    print(\"Starting analysis...\")\n",
    "\n",
    "    # Preprocess the green channel\n",
    "    green = preprocess_green_channel(green)\n",
    "\n",
    "    \n",
    "    #display_image(green, path, \"Green Channel\")\n",
    "\n",
    "    #return green\n",
    "\n",
    "    labeled_cells = segment_cells(green)\n",
    "    #display_image(labeled_cells, path, \"Labeled Cells\")\n",
    "\n",
    "    inclusion_image = generate_inclusion_image(green, labeled_cells)\n",
    "\n",
    "    #display_image(inclusion_image, path, \"Inclusion Image\")\n",
    "\n",
    "\n",
    "    contrast_adjusted_red_normalized = (red - red.min()) / (red.max() - red.min())\n",
    "    threshold_value_mitochondria = np.mean(contrast_adjusted_red_normalized) + (np.std(contrast_adjusted_red_normalized) * 3) #1.75 works well\n",
    "    mitochondria_thresholded = contrast_adjusted_red_normalized > threshold_value_mitochondria\n",
    "    mitochondria_thresholded = remove_small_objects(mitochondria_thresholded, min_size=10)\n",
    "\n",
    "\n",
    "    swiss_cheese_inclusions, regular_inclusions = find_swiss_cheese_inclusions(inclusion_image, mitochondria_thresholded)\n",
    "    #display_image(swiss_cheese_inclusions, path, \"Swiss Cheese Inclusions\")\n",
    "    #display_image(regular_inclusions, path, \"Regular Inclusions\")\n",
    "\n",
    "    #display_image(red, path, \"Red Channel\")\n",
    "    #display_image(mitochondria_thresholded, path, \"Mitochondria Thresholded\")\n",
    "\n",
    "    single, clustered = split_by_circularity(mitochondria_thresholded, 0.7)\n",
    "\n",
    "    #display_image(single, path, \"Single Mitochondria\")\n",
    "    #display_image(clustered, path, \"Clustered Mitochondria\")\n",
    "    cell_count = 1\n",
    "    for i, cell in enumerate(regionprops(labeled_cells)):\n",
    "        if cell.area < 100:  # Skip tiny regions likely to be noise\n",
    "            continue\n",
    "\n",
    "                # Create a mask for the current cell\n",
    "        mask = labeled_cells == cell.label\n",
    "\n",
    "        original_cell = green * mask\n",
    "\n",
    "        inclusions_in_cell = inclusion_image * mask\n",
    "        swiss_cheese_inclusions_in_cell = swiss_cheese_inclusions * mask\n",
    "        regular_inclusions_in_cell = regular_inclusions * mask\n",
    "        mitochondria_in_cell = mitochondria_thresholded * mask\n",
    "        single_mitochondria_in_cell = single * mask\n",
    "        clustered_mitochondria_in_cell = clustered * mask\n",
    "\n",
    "\n",
    "        # single LDS in inclusion \n",
    "        single_ld_in_inclusion, single_ld_in_cyto = seperate_single_LDS(inclusions_in_cell, single_mitochondria_in_cell)\n",
    "        # clustered LDS in inclusion\n",
    "\n",
    "        \n",
    "        clustered_ld_in_inclusion = filter_objects_by_overlap(clustered_mitochondria_in_cell, inclusions_in_cell)\n",
    "\n",
    " \n",
    "\n",
    "        # Calculate average size of inclusions\n",
    "        if count(inclusions_in_cell) > 0:\n",
    "            average_inclusion_size = np.sum(inclusions_in_cell) / count(inclusions_in_cell)\n",
    "        else:\n",
    "            average_inclusion_size = 0\n",
    "\n",
    "\n",
    "        data.append({\n",
    "            'Image Path': path,\n",
    "            'Cell Number': cell_count,\n",
    "            'Cell Area': cell.area,\n",
    "            'Number of Inclusions': count(inclusions_in_cell), \n",
    "            'Number of Swiss Cheese Inclusions': count(swiss_cheese_inclusions_in_cell),  \n",
    "            'Number of Solid Inclusions': count(regular_inclusions_in_cell),  \n",
    "            'Average Size of Inclusion': average_inclusion_size,\n",
    "            'Single LDS in Inclusion': count(single_ld_in_inclusion),\n",
    "            'Single LDS in Cyto': count(single_ld_in_cyto),\n",
    "            'Total Single LDS in Cell': count(single_mitochondria_in_cell),\n",
    "            'Clustered LDS in Inclusion': count(clustered_ld_in_inclusion),\n",
    "            'Clustered LDS in Cyto': count(clustered_mitochondria_in_cell) - count(clustered_ld_in_inclusion),\n",
    "            'Total Clustered LDS in Cell': count(clustered_mitochondria_in_cell),\n",
    "            'Total LDS in Cell': count(mitochondria_in_cell),\n",
    "        })\n",
    "        cell_count += 1\n",
    "\n",
    "    df_cell_summary = pd.DataFrame(data)\n",
    "    return df_cell_summary\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ff3c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n",
      "Starting analysis...\n"
     ]
    }
   ],
   "source": [
    "def main(image_folder):\n",
    "    images_to_analyze = extract_image_paths(image_folder)\n",
    "    output_dir = os.getcwd()\n",
    "    df_cell_summary_list = []\n",
    "\n",
    "    for path in images_to_analyze:\n",
    "        image = read_image(path)\n",
    "        image_squeezed = np.squeeze(image) \n",
    "    \n",
    "        red, green = extract_channels(image_squeezed)\n",
    "\n",
    "        df_cell_summary = analysis(red, green, path)\n",
    "        df_cell_summary_list.append(df_cell_summary)\n",
    "\n",
    "    combined_cell_summary_df = pd.concat(df_cell_summary_list, ignore_index=True)\n",
    "    output_summary_path = os.path.join(output_dir, '061725_SUMMARY.xlsx')\n",
    "    combined_cell_summary_df.to_excel(output_summary_path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_folder = '061725_images'\n",
    "    main(image_folder)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
