{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42981b9b",
   "metadata": {},
   "source": [
    "This code aims to quantify the nuclei and the size and number of synuclein inclusions for single transfections with timecourse, live timecourse, fixed, and plurisin experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c2d49",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7363c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.morphology import remove_small_objects, binary_dilation, disk\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import exposure, morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6954be9f",
   "metadata": {},
   "source": [
    "Define Sub Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19f0502-e11b-49c7-832a-5d7baeeb21b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path):\n",
    "    \"\"\"Extract all image file paths from the specified folder.\"\"\"\n",
    "    return [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "def preprocess_dapi_channel(image):\n",
    "    \"\"\"Extract and preprocess the DAPI channel from the image.\"\"\"\n",
    "    dapi_channel = image[0]\n",
    "    blurred_dapi = gaussian(dapi_channel, sigma=2)  # Smooth the image with Gaussian blur\n",
    "    return blurred_dapi\n",
    "\n",
    "def segment_nuclei(blurred_dapi):\n",
    "    \"\"\"Segment the nuclei from the preprocessed DAPI channel.\"\"\"\n",
    "    threshold_value = threshold_otsu(blurred_dapi)  # Apply Otsu thresholding\n",
    "    binary_image = blurred_dapi > threshold_value  # Convert to binary image\n",
    "    cleaned_image = remove_small_objects(binary_image, min_size=400)  # Remove small objects\n",
    "    return binary_dilation(cleaned_image, footprint=disk(5))  # Dilate the image to merge adjacent objects\n",
    "\n",
    "def count_nuclei(labeled_image):\n",
    "    \"\"\"Count the number of nuclei in the labeled image.\"\"\"\n",
    "    return len(np.unique(labeled_image)) - 1  # Subtract 1 to exclude the background label\n",
    "\n",
    "def preprocess_green_channel(image):\n",
    "    \"\"\"Extract and preprocess the green channel from the image.\"\"\"\n",
    "    green_channel = image[1]\n",
    "    confocal_img = exposure.adjust_sigmoid(green_channel, cutoff=0.4)  # Adjust brightness/contrast\n",
    "    confocal_img = (confocal_img - confocal_img.min()) / (confocal_img.max() - confocal_img.min())  # Normalize\n",
    "    return confocal_img\n",
    "\n",
    "def segment_inclusions(confocal_img, threshold_value=0.19):\n",
    "    \"\"\"Segment inclusions in the green channel using a fixed threshold.\"\"\"\n",
    "    return confocal_img > threshold_value  # Convert to binary image\n",
    "\n",
    "def measure_inclusion_sizes(labeled_image, confocal_img):\n",
    "    \"\"\"Measure the size of each inclusion in the labeled image.\"\"\"\n",
    "    props = regionprops(labeled_image, confocal_img)\n",
    "    return [prop.area for prop in props]  # Extract and return the area of each region\n",
    "\n",
    "def append_to_results(image_sizes, sizes_df, path, iteration):\n",
    "    \"\"\"Append the inclusion sizes to the DataFrame for all images.\"\"\"\n",
    "    sizes_df_add = pd.DataFrame(image_sizes, columns=[f'image {path}'])\n",
    "    if iteration == 1:\n",
    "        return sizes_df_add\n",
    "    return pd.concat([sizes_df, sizes_df_add], axis=1)\n",
    "\n",
    "def clean_up_dataframe(sizes_df):\n",
    "    \"\"\"Clean up the DataFrame by replacing 1s with NaN and shifting values.\"\"\"\n",
    "    sizes_df = sizes_df.replace(1.0, np.NaN)\n",
    "    return sizes_df.apply(lambda x: pd.Series(x.dropna().values))\n",
    "\n",
    "def finalize_and_save_results(sizes_df, number_of_nuclei_list):\n",
    "    \"\"\"Finalize the results, calculate metrics, and save them to Excel files.\"\"\"\n",
    "    sizes_df = clean_up_dataframe(sizes_df)\n",
    "    sizes_df_new_nuclei = sizes_df.transpose()\n",
    "    number_of_inclusions = sizes_df_new_nuclei.count(axis=1)\n",
    "    average_number_of_inclusions = number_of_inclusions / number_of_nuclei_list\n",
    "\n",
    "    excel_2 = pd.DataFrame({\n",
    "        'Number_of_Inclusions': number_of_inclusions,\n",
    "        'Number_of_Nuclei': number_of_nuclei_list,\n",
    "        'Average_Number_of_Inclusions_per_Cell': average_number_of_inclusions\n",
    "    })\n",
    "\n",
    "    excel_2.to_excel(\"SIZES.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58a2ee2",
   "metadata": {},
   "source": [
    "Define Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830021e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(folder_path):\n",
    "    \"\"\"Main function to process images and save results.\"\"\"\n",
    "    image_files = load_images_from_folder(folder_path)\n",
    "    sizes_df = pd.DataFrame()\n",
    "    number_of_nuclei_list = []\n",
    "\n",
    "    for iteration, image_path in enumerate(image_files, start=1):\n",
    "        image = imread(image_path)\n",
    "\n",
    "        # Process DAPI channel to count nuclei\n",
    "        blurred_dapi = preprocess_dapi_channel(image)\n",
    "        labeled_nuclei = label(segment_nuclei(blurred_dapi))\n",
    "        n_nuclei = count_nuclei(labeled_nuclei)\n",
    "        number_of_nuclei_list.append(n_nuclei)\n",
    "\n",
    "        # Process green channel to count inclusions\n",
    "        confocal_img = preprocess_green_channel(image)\n",
    "        labeled_inclusions = label(segment_inclusions(confocal_img))\n",
    "        inclusion_sizes = measure_inclusion_sizes(labeled_inclusions, confocal_img)\n",
    "        sizes_df = append_to_results(inclusion_sizes, sizes_df, image_path, iteration)\n",
    "\n",
    "    finalize_and_save_results(sizes_df, number_of_nuclei_list)\n",
    "\n",
    "# Run the main function on the folder with images\n",
    "main(\"test_images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
