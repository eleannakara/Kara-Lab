{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sj1205\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\cellpose\\resnet_torch.py:275: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(filename, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import gaussian, threshold_otsu, threshold_multiotsu, sobel\n",
    "from skimage.morphology import remove_small_objects, disk, binary_closing\n",
    "from scipy.ndimage import zoom, binary_dilation, binary_erosion\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import io, exposure, color\n",
    "from skimage import measure, morphology\n",
    "from skimage import exposure\n",
    "from czifile import imread\n",
    "from cellpose import models, plot \n",
    "from scipy.stats import skew\n",
    "import cv2\n",
    "import re\n",
    "model = models.Cellpose(gpu=False, model_type='cyto3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_INCLUSION_SIZE = 10\n",
    "MAX_INCLUSION_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, path, type):\n",
    "    \"\"\"Display the image.\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{path} {type}\")\n",
    "    plt.show()\n",
    "\n",
    "def extract_image_paths(folder):\n",
    "    \"\"\"Extract all image file paths from the specified folder.\"\"\"\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"Read the LSM image from the specified path.\"\"\"\n",
    "    return imread(image_path)\n",
    "\n",
    "def extract_channels(image: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Extract green and red channels from the squeezed image (shape: [Z, C, H, W]).\"\"\" \n",
    "    return image[0], image[1]\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize the image to the range [0, 1].\n",
    "    This is useful for consistent processing across different images.\n",
    "    \"\"\"\n",
    "    return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "\n",
    "def segment_cells(green_channel):\n",
    "    \"\"\"\n",
    "    Segment whole cells in the green channel using Cellpose.\n",
    "    - Normalizes image intensity.\n",
    "    - Suppresses bright spots (e.g., inclusions) to better detect cell boundaries.\n",
    "    - Applies Gaussian blur for smoother segmentation input.\n",
    "    - Gradually increases segmentation diameter until at least one cell is detected.\n",
    "    \"\"\"\n",
    "    green_channel = normalize_image(green_channel)\n",
    "    percentile_99 = np.percentile(green_channel, 99)\n",
    "    \n",
    "    # Suppress very bright pixels (inclusions)\n",
    "    green_channel_remove_inclusions = np.where(green_channel < percentile_99, green_channel, percentile_99)\n",
    "    green_channel_remove_inclusions = gaussian(green_channel_remove_inclusions, sigma=5)\n",
    "\n",
    "    # Normalize again after processing\n",
    "    green_channel_remove_inclusions = normalize_image(green_channel_remove_inclusions)\n",
    "\n",
    "    # Try different diameters until cells are detected\n",
    "    diameter = 150\n",
    "    while diameter < 500:\n",
    "        masks, flows, styles, diams = model.eval(green_channel_remove_inclusions, diameter=diameter, channels=[0, 0])\n",
    "        labeled_cells = label(masks)\n",
    "        if np.max(labeled_cells) > 0:\n",
    "            return labeled_cells\n",
    "        diameter += 25\n",
    "\n",
    "    # No cells found\n",
    "    return None\n",
    "\n",
    "def extract_inclusions(green_channel, mask, cell_number, path, display_graph=False):\n",
    "    applied_mask_blurred = gaussian(green_channel, sigma=1) * mask\n",
    "    applied_mask_eliminate_background = applied_mask_blurred[applied_mask_blurred > 0]\n",
    "\n",
    "\n",
    "    # Normalize the signal within the masked region\n",
    "    applied_mask_eliminate_background = normalize_image(applied_mask_eliminate_background)\n",
    "\n",
    "\n",
    "    # Compute descriptive statistics for intensity distribution\n",
    "    q3 = np.percentile(applied_mask_eliminate_background, 75)\n",
    "    hist, bin_edges = np.histogram(applied_mask_eliminate_background, bins='fd')\n",
    "    applied_mask = green_channel * mask\n",
    "    cell_size = np.count_nonzero(mask)\n",
    "    #if (cell_size < 400):\n",
    "    #    inclusions = applied_mask > 0.6\n",
    "    #    inclusions = remove_small_objects(inclusions, min_size=MIN_INCLUSION_SIZE)\n",
    "    #    inclusions = inclusions ^ remove_small_objects(inclusions, min_size=MAX_INCLUSION_SIZE)\n",
    "    #    return inclusions\n",
    "\n",
    "    skewness = skew(applied_mask_eliminate_background)\n",
    "\n",
    "    # Decide on thresholding strategy based on upper quartile\n",
    "    if skewness > 0.25:\n",
    "        threshold = max(threshold_otsu(applied_mask), 0.5)\n",
    "    #elif skewness < -0.5:\n",
    "    #    threshold = 0.6  # very high, to exclude everything\n",
    "    #else:\n",
    "    #    threshold = 0.999  # conservatively high\n",
    "    else:\n",
    "\n",
    "        threshold = 0.75\n",
    "\n",
    "\n",
    "    # Apply threshold and size-based filters\n",
    "    inclusions = applied_mask > threshold\n",
    "    inclusions = remove_small_objects(inclusions, min_size=MIN_INCLUSION_SIZE)\n",
    "    inclusions = inclusions ^ remove_small_objects(inclusions, min_size=MAX_INCLUSION_SIZE)\n",
    "    if display_graph:\n",
    "        print(\"Threshold: \", threshold)\n",
    "        print(\"Bin count\", len(bin_edges))\n",
    "        print( f\"cell number: {cell_number} cell size: {cell_size} skewness: {skewness}\")\n",
    "        plt.hist(applied_mask_eliminate_background, bins='fd')\n",
    "        plt.axvline(q3, color='purple', linestyle='dashed', linewidth=2, label=f'Q3: {q3:.2f}')\n",
    "        plt.legend()\n",
    "        plt.title(\"Intensity histogram\")\n",
    "        plt.show()\n",
    "\n",
    "    return inclusions\n",
    "\n",
    "def generate_inclusion_image(green_channel, labeled_cells, path):\n",
    "    \"\"\"\n",
    "    Generate a binary image with all inclusions from all cells.\n",
    "    - Loops through each segmented cell.\n",
    "    - Extracts inclusions from each cell region.\n",
    "    - Combines all into one final binary image.\n",
    "    \"\"\"\n",
    "    inclusion_image = np.zeros_like(green_channel)\n",
    "\n",
    "    for i, cell in enumerate(regionprops(labeled_cells)):\n",
    "        if cell.area < 100:\n",
    "            continue\n",
    "        mask = labeled_cells == cell.label\n",
    "        #display_image(mask, \"mask\", f\"cell {i + 1}\")\n",
    "        inclusions = extract_inclusions(green_channel, mask, i +1, path)\n",
    "        inclusion_image += inclusions  # adds binary inclusion mask\n",
    "\n",
    "    return inclusion_image\n",
    "\n",
    "def preprocess_green_channel(green_channel):\n",
    "    \"\"\"\n",
    "    Preprocess the green fluorescence channel for better segmentation and inclusion detection.\n",
    "    - Applies Gaussian blur to reduce noise.\n",
    "    - Enhances contrast using sigmoid adjustment.\n",
    "    - Normalizes intensities to [0, 1] for consistent processing.\n",
    "    \"\"\"\n",
    "    confocal_img = gaussian(green_channel, sigma=2)\n",
    "    confocal_img = exposure.adjust_sigmoid(green_channel, cutoff=0.25)\n",
    "    confocal_img = normalize_image(confocal_img)\n",
    "    return confocal_img\n",
    "\n",
    "def circularity_filter(mask: np.ndarray, threshold: float = 0.7):\n",
    "    \"\"\"\n",
    "    Splits a binary mask into two masks based on circularity index.\n",
    "\n",
    "    Parameters:\n",
    "        mask (np.ndarray): Binary input mask (dtype=bool or 0/1).\n",
    "        threshold (float): Circularity threshold to split regions.\n",
    "\n",
    "    Returns:\n",
    "        mask_high_circularity (np.ndarray): Mask with circular objects (circularity > threshold).\n",
    "        mask_low_circularity (np.ndarray): Mask with less circular objects (circularity <= threshold).\n",
    "    \"\"\"\n",
    "\n",
    "    labeled = label(mask)\n",
    "    high_circularity_mask = np.zeros_like(mask, dtype=bool)\n",
    "    low_circularity_mask = np.zeros_like(mask, dtype=bool)\n",
    "\n",
    "    for region in regionprops(labeled):\n",
    "        perimeter = region.perimeter\n",
    "        area = region.area\n",
    "\n",
    "        if perimeter == 0:\n",
    "            continue  # Skip degenerate shapes\n",
    "\n",
    "        circularity = 4 * np.pi * (area / (perimeter ** 2))\n",
    "\n",
    "        coords = tuple(zip(*region.coords))\n",
    "        if circularity > threshold:\n",
    "            high_circularity_mask[coords] = True\n",
    "        else:\n",
    "            low_circularity_mask[coords] = True\n",
    "\n",
    "    return high_circularity_mask, low_circularity_mask\n",
    "\n",
    "\n",
    "def calculate_surface_area(labeled_image: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the total surface area for labeled regions.\"\"\"\n",
    "    props = regionprops(labeled_image)\n",
    "    return sum(prop.area for prop in props)\n",
    "\n",
    "def count_overlapping_regions(red_labeled, inclusion_mask):\n",
    "    count = 0\n",
    "    for region in regionprops(red_labeled):\n",
    "        red_mask = np.zeros_like(inclusion_mask, dtype=bool)\n",
    "        coords = tuple(zip(*region.coords))\n",
    "        red_mask[coords] = True\n",
    "        if np.any(red_mask & inclusion_mask):\n",
    "            count += 1\n",
    "    return count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(red, green, path):\n",
    "    data = []\n",
    "    #green_channel = preprocess_green_channel(green)\n",
    "    ##display_image(green_channel, path, \"Preprocessed Green Channel\")\n",
    "#\n",
    "    ## Segment individual cells from the green channel\n",
    "    #labeled_cells = segment_cells(green_channel)\n",
    "    #display_image(labeled_cells, path, \"Labeled Cells\")\n",
    "    #inclusions_image = generate_inclusion_image(green_channel, labeled_cells, path)\n",
    "    #display_image(inclusions_image, path, \"Inclusions Image\")\n",
    "    \n",
    "    red_channel = normalize_image(red)\n",
    "    red_channel = red_channel > threshold_otsu(red_channel)\n",
    "    red_channel = remove_small_objects(red_channel, min_size=20)\n",
    "    \n",
    "    #display_image(red_channel, path, \"Red Channel\")\n",
    "\n",
    "    green_channel = preprocess_green_channel(green)\n",
    "    labeled_cells = segment_cells(green_channel)\n",
    "    for i, cell in enumerate(regionprops(labeled_cells)):\n",
    "        if cell.area < 100:  # Skip tiny regions likely to be noise\n",
    "            continue\n",
    "\n",
    "        # Create a mask for the current cell\n",
    "        mask = labeled_cells == cell.label\n",
    "\n",
    "        # Detect inclusions within the cell mask in the green channel\n",
    "        inclusions = extract_inclusions(green_channel, mask, i+1, path)\n",
    "        inclusions_labeled = label(inclusions)\n",
    "\n",
    "        #find red_channel within this cell\n",
    "        red_channel_cell = red_channel * mask\n",
    "        red_channel_single, red_channel_clustered = circularity_filter(red_channel_cell, threshold=0.8)\n",
    "\n",
    "        # Count the number of inclusions\n",
    "        num_inclusions = len(regionprops(inclusions_labeled))\n",
    "        # average size of the inclusions\n",
    "        inclusion_size_average = np.mean([region.area for region in regionprops(inclusions_labeled)]) if num_inclusions > 0 else 0\n",
    "        inclusion_regions = regionprops(inclusions_labeled)\n",
    "        # if there is an overlap between the red and inclusions find the number of those occurences\n",
    "        num_swiss_cheese_inclusions = 0\n",
    "        for region in inclusion_regions:\n",
    "            inclusion_mask = np.zeros_like(inclusions, dtype=bool)\n",
    "            coords = tuple(zip(*region.coords))\n",
    "            inclusion_mask[coords] = True\n",
    "            if np.any(red_channel_cell & inclusion_mask):\n",
    "                num_swiss_cheese_inclusions += 1\n",
    "\n",
    "        num_non_swiss_cheese_inclusions = num_inclusions - num_swiss_cheese_inclusions\n",
    "\n",
    "        # find if there is an overlap between red and the inclusions\n",
    "\n",
    "\n",
    "\n",
    "        overlap_area = red_channel_cell * inclusions\n",
    "\n",
    "        red_single_labeled = label(red_channel_single)\n",
    "        red_clustered_labeled = label(red_channel_clustered)\n",
    "\n",
    "\n",
    "        num_overlapping_red_single = count_overlapping_regions(red_single_labeled, inclusions)\n",
    "        num_overlapping_red_clustered = count_overlapping_regions(red_clustered_labeled, inclusions)\n",
    "\n",
    "\n",
    "        data.append({\n",
    "            'Filename': path,\n",
    "            'Cell Number': i + 1,\n",
    "            'Number of Inclusions': num_inclusions,\n",
    "            'Average Inclusion Size': inclusion_size_average,\n",
    "            'Number of Swiss Cheese Inclusions': num_swiss_cheese_inclusions,\n",
    "            'Number of Non-Swiss Cheese Inclusions': num_non_swiss_cheese_inclusions,\n",
    "            'Number of Lipid Droplets': len(regionprops(label(red_channel_cell))),\n",
    "            'Surface area of Green': calculate_surface_area(inclusions_labeled),\n",
    "            'Surface area of Red': calculate_surface_area(label(red_channel_cell)),\n",
    "            'Surface area of overlap': calculate_surface_area(label(overlap_area)),\n",
    "            'Number of Overlapping Red Single': num_overlapping_red_single,\n",
    "            'Number of Overlapping Red Clustered': num_overlapping_red_clustered,\n",
    "        })\n",
    "\n",
    "    df_cell_summary = pd.DataFrame(data)\n",
    "\n",
    "    return df_cell_summary\n",
    "       \n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(image_folder):\n",
    "    images_to_analyze = extract_image_paths(image_folder)\n",
    "    output_dir = os.getcwd()\n",
    "\n",
    "\n",
    "    df_summary = []\n",
    "    \n",
    "    for path in images_to_analyze:\n",
    "        image = read_image(path)\n",
    "        image_squeezed = np.squeeze(image) \n",
    "\n",
    "        red, green = extract_channels(image_squeezed)\n",
    "        df_cell_summary = analysis(red, green, path)\n",
    "        df_summary.append(df_cell_summary)\n",
    "\n",
    "    combined_cell_summary_df = pd.concat(df_summary, ignore_index=True)\n",
    "    output_summary_path = os.path.join(output_dir, '4825_3K.xlsx')\n",
    "    combined_cell_summary_df.to_excel(output_summary_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_folder = '4825_images/3K/new settings'\n",
    "    main(image_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
