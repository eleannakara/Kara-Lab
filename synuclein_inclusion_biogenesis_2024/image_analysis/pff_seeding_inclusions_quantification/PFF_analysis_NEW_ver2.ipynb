{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9706e858",
   "metadata": {},
   "source": [
    "The purpose of this code is to quantify the nuclei, the size and number of synuclein inclusions for each image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27bf2f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d30d31b",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15984f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import gaussian, threshold_otsu, threshold_multiotsu\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import remove_small_objects, binary_dilation, disk\n",
    "import czifile\n",
    "import skimage.io as io\n",
    "from skimage import exposure\n",
    "from cellpose import models\n",
    "model = models.Cellpose(model_type='cyto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43beac27",
   "metadata": {},
   "source": [
    "Define Sub Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040cf366",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_INCLUSION_SIZE = 10\n",
    "MAX_INCLUSION_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df11f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    io.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def preprocess_green_channel(green_channel):\n",
    "    \"\"\"Preprocess the green channel for cell segmentation and inclusion quantification.\"\"\"\n",
    "    confocal_img = gaussian(green_channel, sigma=2)\n",
    "    confocal_img = exposure.adjust_sigmoid(green_channel, cutoff=0.25)\n",
    "    confocal_img = (confocal_img - confocal_img.min()) / (confocal_img.max() - confocal_img.min())\n",
    "    \n",
    "    return confocal_img\n",
    "\n",
    "def preprocess_dapi_channel(dapi_channel):\n",
    "    \"\"\"Preprocess the DAPI channel for nuclei quantification.\"\"\"\n",
    "    blurred_dapi = gaussian(dapi_channel, sigma=2)\n",
    "    threshold_value = threshold_otsu(blurred_dapi)\n",
    "    binary_image = blurred_dapi > threshold_value\n",
    "    # show_image(binary_image)\n",
    "    cleaned_image = remove_small_objects(binary_image, min_size=400)\n",
    "    merged_image = binary_dilation(cleaned_image, footprint=disk(5))\n",
    "    labeled_image = label(merged_image)\n",
    "    return labeled_image\n",
    "\n",
    "def count_nuclei(labeled_image):\n",
    "    \"\"\"Count the number of nuclei in the labeled image.\"\"\"\n",
    "    return len(np.unique(labeled_image)) - 1\n",
    "\n",
    "\n",
    "def segment_cells(green_channel):\n",
    "    \"\"\"Segment cells in the green channel.\"\"\"\n",
    "    # normalize the green channel\n",
    "    green_channel = (green_channel - np.min(green_channel)) / (np.max(green_channel) - np.min(green_channel))\n",
    "    median_intensity = np.median(green_channel)\n",
    "    percentile_99 = np.percentile(green_channel, 99)\n",
    "    # print(\"Mean Intensity: \", mean_intensity)\n",
    "    green_channel_remove_inclusions = np.where(green_channel < percentile_99, green_channel, percentile_99) # dim down inclusions\n",
    "    green_channel_remove_inclusions = gaussian(green_channel_remove_inclusions, sigma=5) # blur\n",
    "    show_image(green_channel_remove_inclusions)\n",
    "\n",
    "    \n",
    "    # normalize\n",
    "    green_channel_remove_inclusions = (green_channel_remove_inclusions - np.min(green_channel_remove_inclusions)) / ((np.max(green_channel_remove_inclusions) - np.min(green_channel_remove_inclusions)))\n",
    "    # show_image(green_channel_remove_inclusions)\n",
    "\n",
    "    # Detect cells in the green channel\n",
    "    # keep increasing diameter until cells are detected\n",
    "    diameter = 150\n",
    "\n",
    "    while diameter < 500:\n",
    "\n",
    "        masks, flows, styles, diams = model.eval(green_channel_remove_inclusions, diameter=diameter, channels=[0, 0])\n",
    "        labeled_cells = label(masks)\n",
    "        # if there are more than 0 cells\n",
    "        if np.max(labeled_cells) > 0:\n",
    "            return labeled_cells\n",
    "        diameter += 25\n",
    "    # no cells found, throw an error\n",
    "    return None\n",
    "\n",
    "def extract_inclusions(green_channel,mask,display_graph=False):\n",
    "    applied_mask_blurred = gaussian(green_channel, sigma=1) * mask\n",
    "    applied_mask_eliminate_background = applied_mask_blurred[applied_mask_blurred > 0] # filter out 0\n",
    "    \n",
    "    # normalize \n",
    "    applied_mask_eliminate_background = (applied_mask_eliminate_background - np.min(applied_mask_eliminate_background)) / ((np.max(applied_mask_eliminate_background) - np.min(applied_mask_eliminate_background)))\n",
    "\n",
    "    # calculate statistics\n",
    "    mean_intensity = np.mean(applied_mask_eliminate_background)\n",
    "    median_intensity = np.median(applied_mask_eliminate_background)\n",
    "    q1 = np.percentile(applied_mask_eliminate_background, 25)\n",
    "    q3 = np.percentile(applied_mask_eliminate_background, 75)\n",
    "    \n",
    "    hist, bin_edges = np.histogram(applied_mask_eliminate_background, bins='fd')\n",
    "    \n",
    "    applied_mask = green_channel * mask\n",
    "    # 0.4 is an empirical value that seems to work well\n",
    "    if q3 < 0.4 and len(bin_edges) > 20:\n",
    "        # the population is skewed to the left, indicating that there are inclusions\n",
    "        threshold = max(threshold_otsu(applied_mask),0.5) # use otsu thresholding to find the threshold\n",
    "    elif q3 >= 0.9:\n",
    "        # definitely no inclusions\n",
    "        threshold = 1\n",
    "    else:\n",
    "        # probably no inclusions, but not sure, so we set a very high threshold in case there are inclusions\n",
    "        threshold = 0.999\n",
    "    \n",
    "    inclusions = applied_mask > threshold # apply the threshold\n",
    "\n",
    "    inclusions = remove_small_objects(inclusions, min_size=MIN_INCLUSION_SIZE) # remove small objects\n",
    "    inclusions = inclusions ^ remove_small_objects(inclusions, min_size=MAX_INCLUSION_SIZE) # remove large objects\n",
    "    \n",
    "    if display_graph:\n",
    "        \n",
    "        print(\"Threshold: \", threshold)\n",
    "        print(\"Bin count\", len(bin_edges))\n",
    "\n",
    "        plt.hist(applied_mask_eliminate_background, bins='fd')  \n",
    "        plt.axvline(mean_intensity, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_intensity:.2f}')\n",
    "        plt.axvline(median_intensity, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median_intensity:.2f}')\n",
    "        plt.axvline(q1, color='blue', linestyle='dashed', linewidth=2, label=f'Q1: {q1:.2f}')\n",
    "        plt.axvline(q3, color='purple', linestyle='dashed', linewidth=2, label=f'Q3: {q3:.2f}')\n",
    "        plt.legend()\n",
    "        plt.title(\"Intensity histogram\")\n",
    "        plt.show()\n",
    "\n",
    "    return inclusions\n",
    "\n",
    "def generate_inclusion_image(green_channel, labeled_cells):\n",
    "    inclusion_image = np.zeros_like(green_channel)\n",
    "\n",
    "    for i, cell in enumerate(regionprops(labeled_cells)):\n",
    "        if cell.area < 100:\n",
    "            continue\n",
    "        \n",
    "        mask = labeled_cells == cell.label\n",
    "        \n",
    "        inclusions = extract_inclusions(green_channel, mask)\n",
    "\n",
    "        inclusion_image += inclusions\n",
    "    # show_image(inclusion_image)\n",
    "    return inclusion_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966def43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(image_path, basename):\n",
    "    \"\"\"\n",
    "    Analyze an image by its individual cells\n",
    "    Args:\n",
    "        image_path: Path to the .czi image file.\n",
    "        basename: Base name for the file, used in the output DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing details about each image \n",
    "        A second DataFrame containing details about each detected cell\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the image and squeeze dimensions\n",
    "    image = czifile.imread(image_path)\n",
    "    image_squeezed = np.squeeze(image)\n",
    "\n",
    "    # Separate the channels\n",
    "    green_channel = image_squeezed[0, :, :]\n",
    "    dapi_channel = image_squeezed[1, :, :]\n",
    "\n",
    "    green_channel = preprocess_green_channel(green_channel)\n",
    "    print(\"Green Channel\")\n",
    "    show_image(green_channel)\n",
    "\n",
    "    # Process DAPI channel for nuclei counting\n",
    "    labeled_image_dapi = preprocess_dapi_channel(dapi_channel)\n",
    "    num_nuclei = count_nuclei(labeled_image_dapi)\n",
    "\n",
    "    labeled_cells = segment_cells(green_channel)\n",
    "    \n",
    "    print(\"Segmented Cells\")\n",
    "    show_image(labeled_cells)\n",
    "\n",
    "\n",
    "    # Initialize lists to store results\n",
    "    cell_counter = []\n",
    "    cell_size = []\n",
    "    num_inclusions = []\n",
    "    total_inclusion_areas = []\n",
    "    average_inclusion_areas = []\n",
    "\n",
    "    inclusion_areas_list = []\n",
    "    inclusion_counter = []\n",
    "    inclusion_counter_cells = []\n",
    "\n",
    "    # Analyze each detected cell\n",
    "    for i, cell in enumerate(regionprops(labeled_cells)):\n",
    "        if cell.area < 100:\n",
    "            continue\n",
    "        \n",
    "        cell_counter.append(i)\n",
    "        cell_size.append(cell.area)\n",
    "        \n",
    "        mask = labeled_cells == cell.label\n",
    "        \n",
    "        inclusions = extract_inclusions(green_channel, mask, display_graph=True) # extract inclusions from the green channel\n",
    "        \n",
    "        inclusions_labeled = label(inclusions)\n",
    "        \n",
    "        inclusion_areas = [inclusion.area for inclusion in regionprops(inclusions_labeled)] \n",
    "        if len(inclusion_areas) > 0:\n",
    "            show_image(inclusions)\n",
    "            print(f\"Cell {i}: Number of inclusions: {len(inclusion_areas)}\")\n",
    "            print(f\"Cell {i}: Inclusion areas: {inclusion_areas}\")\n",
    "        inclusion_areas = np.array(inclusion_areas)\n",
    "        total_inclusion_area = np.sum(inclusion_areas)\n",
    "        average_inclusion_area = np.mean(inclusion_areas)\n",
    "        \n",
    "        \n",
    "        # store results\n",
    "        total_inclusion_areas.append(total_inclusion_area)\n",
    "        num_inclusions.append(len(inclusion_areas))\n",
    "        inclusion_areas_list.append(inclusion_areas)\n",
    "        inclusion_counter.append(range(len(inclusion_areas)))\n",
    "        inclusion_counter_cells.append([i] * len(inclusion_areas))\n",
    "        average_inclusion_areas.append(average_inclusion_area)\n",
    "\n",
    "    \n",
    "    # analysis by image\n",
    "    df1 = pd.DataFrame({\n",
    "        \"File_Name:\": [basename],\n",
    "        \"Number_of_Inclusions\": [np.sum(num_inclusions)],\n",
    "        \"Number_of_Nuclei\": [num_nuclei],\n",
    "        \"Number_of_Inclusions_per_Nucleus\": [np.sum(num_inclusions) / num_nuclei],\n",
    "    })\n",
    "    \n",
    "    # analysis by cell\n",
    "    df2 = pd.DataFrame({\n",
    "        \"File_Name\": [basename] * len(cell_counter),\n",
    "        \"Cell\": cell_counter,\n",
    "        \"Num_Inclusions\": num_inclusions\n",
    "    })\n",
    "    \n",
    "    # analysis by inclusion\n",
    "    if len(inclusion_counter) == 0:\n",
    "        df3 = pd.DataFrame()\n",
    "    else:\n",
    "        df3 = pd.DataFrame({\n",
    "            \"File_Name\": [basename] * len(np.concatenate(inclusion_counter)),\n",
    "            \"Inclusion\": np.concatenate(inclusion_counter),\n",
    "            \"Cell\": np.concatenate(inclusion_counter_cells),\n",
    "            \"Inclusion_Area\": np.concatenate(inclusion_areas_list)\n",
    "        })\n",
    "\n",
    "    \n",
    "    return df1, df2, df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112fe69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_images(image_folder):\n",
    "    all_data_1 = []\n",
    "    all_data_2 = []\n",
    "    all_data_3 = []\n",
    "    for well_image in os.listdir(image_folder):\n",
    "        \n",
    "        if well_image.lower().endswith(\".czi\"):  # Filter for CZI files\n",
    "            \n",
    "            print(well_image)\n",
    "\n",
    "            well_image_path = os.path.join(image_folder, well_image)\n",
    "            well_image_base_name = os.path.basename(well_image)[:-4]\n",
    "            \n",
    "            df1, df2, df3 = analyze_image(well_image_path, well_image_base_name)\n",
    "            all_data_1.append(df1)\n",
    "            all_data_2.append(df2)\n",
    "            all_data_3.append(df3)\n",
    "            \n",
    "            print(\"-\" * 200)\n",
    "\n",
    "    combined_df_1 = pd.concat(all_data_1, ignore_index=True)\n",
    "    combined_df_1.to_excel(f\"{image_folder[:6]}_analysis_by_image_NEW.xlsx\", index=False)\n",
    "\n",
    "    combined_df_2 = pd.concat(all_data_2, ignore_index=True)\n",
    "    combined_df_2.to_excel(f\"{image_folder[:6]}_analysis_by_cell_NEW.xlsx\", index=False)\n",
    "\n",
    "    combined_df_3 = pd.concat(all_data_3, ignore_index=True)\n",
    "    combined_df_3.to_excel(f\"{image_folder[:6]}_analysis_by_inclusion_NEW.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a3f383",
   "metadata": {},
   "source": [
    "Define Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97adf20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['011124_PFF_SCR_TAX_ADAM/new settings', '251024_PFF_SCR_TAX_ADAM', '281024_PFF_SCR_TAX_ADAM_800/new new settings','291024_PFF_SCR_TAX_ADAM_780', '120524_PFF_SCR_TAX_ADAM_800']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fcf244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analyze_all_images(folders[0])\n",
    "# for folder in folders:\n",
    "#     analyze_all_images(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cefc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_all_images(folders[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_all_images(folders[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f4dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_all_images(folders[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b044fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_all_images(folders[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5f431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246cba3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab12780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
