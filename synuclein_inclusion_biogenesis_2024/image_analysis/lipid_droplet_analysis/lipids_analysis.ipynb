{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "040207fc",
   "metadata": {},
   "source": [
    "The purpose of this code is to compute metrics quantifying the morphology and number of lipid droplets to analyze the behavior of lipids in-cell under various conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7176bc7-3778-4b14-8779-b84d6ff70800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from skimage import segmentation, measure\n",
    "from scipy import ndimage\n",
    "from skimage import exposure, filters, measure\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology\n",
    "from skimage.filters import gaussian\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import binary_dilation, disk\n",
    "import pandas as pd\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.morphology import remove_small_objects\n",
    "from PIL import Image, ImageEnhance\n",
    "from skimage.morphology import binary_dilation, disk\n",
    "import skimage\n",
    "import czifile\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from skimage import measure, util\n",
    "\n",
    "\n",
    "def calculate_circularity(area, perimeter):\n",
    "    circularity = (4 * np.pi * area) / (perimeter**2)\n",
    "    return circularity\n",
    "\n",
    "def sigmoid_contrast_adjustment(image, gain=100, bias=0.1): \n",
    "    adjusted_image = 1 / (1 + np.exp(-gain * (image - bias))) \n",
    "    return adjusted_image \n",
    "\n",
    "def quantify_lipid_inside_inclusions(image_path, inclusion_mask_path, lipid_mask_path):\n",
    "    # Read the image, inclusion mask, and lipid mask\n",
    "    image = cv2.imread(image_path)\n",
    "    inclusion_mask = cv2.imread(inclusion_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    lipid_mask = cv2.imread(lipid_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Threshold the lipid mask to segment lipid droplets\n",
    "    _, lipid_binary = cv2.threshold(lipid_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "    # Find contours of lipid droplets and inclusions\n",
    "    lipid_contours, _ = cv2.findContours(lipid_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    inclusion_contours, _ = cv2.findContours(inclusion_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Initialize counter for lipid droplets inside inclusions\n",
    "    num_lipid_inside_inclusions = 0\n",
    "    # Loop through each lipid droplet and check if it's inside any inclusion\n",
    "    for lipid_contour in lipid_contours:\n",
    "        for inclusion_contour in inclusion_contours:\n",
    "            # Check if the bounding rectangles of lipid and inclusion overlap\n",
    "            if (cv2.boundingRect(lipid_contour)[0] >= cv2.boundingRect(inclusion_contour)[0] and \\\n",
    "               cv2.boundingRect(lipid_contour)[0] + cv2.boundingRect(lipid_contour)[2] <= cv2.boundingRect(inclusion_contour)[0] + cv2.boundingRect(inclusion_contour)[2] and \\\n",
    "               cv2.boundingRect(lipid_contour)[1] >= cv2.boundingRect(inclusion_contour)[1] and \\\n",
    "               cv2.boundingRect(lipid_contour)[1] + cv2.boundingRect(lipid_contour)[3] <= cv2.boundingRect(inclusion_contour)[1] + cv2.boundingRect(inclusion_contour)[3]):\n",
    "                num_lipid_inside_inclusions += 1\n",
    "                break  # Break the inner loop if the lipid is inside any inclusion\n",
    "\n",
    "    # Calculate the percentage of lipid droplets inside inclusions\n",
    "    total_lipid_droplets = len(lipid_contours)\n",
    "    percentage_inside_inclusions = (num_lipid_inside_inclusions / total_lipid_droplets) * 100\n",
    "    return percentage_inside_inclusions\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "def quantify_inclusion_structure(inclusion_mask):\n",
    "    cv_image = cv2.imread(inclusion_mask, cv2.IMREAD_GRAYSCALE)\n",
    "    cv_image = cv2.resize(cv_image, (956, 956))\n",
    "    _, binary_mask = cv2.threshold(cv_image, 1, 255, cv2.THRESH_BINARY)\n",
    "    # Find contours of inclusions\n",
    "    contours, hierarchy = cv2.findContours(binary_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_tree, hierarchy_tree = cv2.findContours(binary_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    blank_image = np.zeros((binary_mask.shape[0],binary_mask.shape[0],3), np.uint8)\n",
    "    # Initialize counters\n",
    "    num_solid_inclusions = 0\n",
    "    num_hollow_inclusions = 0\n",
    "    count = 0\n",
    "    all_child_contour_areas = []\n",
    "    save_child_indices = []\n",
    "    # Loop through each inclusion and check its structure\n",
    "    for i in range(0,len(contours_tree)):\n",
    "        if(hierarchy_tree[0][i][2] != -1):\n",
    "            if(cv2.contourArea(contours_tree[i]) >=10):\n",
    "                child_contour_area = cv2.contourArea(contours_tree[hierarchy_tree[0][i][2]])\n",
    "                if(child_contour_area >= 5):\n",
    "                    save_child_indices.append(hierarchy_tree[0][i][2])\n",
    "                    all_child_contour_areas.append(child_contour_area)\n",
    "        if(hierarchy_tree[0][i][2] == -1):\n",
    "            if(cv2.contourArea(contours_tree[i]) >=10):\n",
    "                num_solid_inclusions = num_solid_inclusions + 1\n",
    "\n",
    "    for i in range(0,len(all_child_contour_areas)):\n",
    "        if(all_child_contour_areas[i]==152.5):\n",
    "            image = cv2.drawContours(blank_image, contours, save_child_indices[i], (0, 0, 255), 2) \n",
    "        if(all_child_contour_areas[i] >= 10):\n",
    "            num_hollow_inclusions = num_hollow_inclusions + 1\n",
    "        \n",
    "    # Calculate the percentage of solid and holed inclusions\n",
    "    total_inclusions = num_hollow_inclusions + num_solid_inclusions\n",
    "    ave_child_inclusion_size = np.mean(all_child_contour_areas)\n",
    "    percentage_solid = (num_solid_inclusions / total_inclusions) * 100\n",
    "    percentage_hollow = (num_hollow_inclusions / total_inclusions) * 100\n",
    "    return all_child_contour_areas, total_inclusions, num_hollow_inclusions, percentage_solid, percentage_hollow\n",
    "\n",
    "\n",
    "images_to_analyze = [f for f in listdir(\"test_images\") if isfile(join(\"test_images\", f))]\n",
    "number_of_nuclei_list = []\n",
    "number_of_inclusions_list = []\n",
    "percent_SA_lipids_list = []\n",
    "percent_SA_lipids_list_inclusions = []\n",
    "percent_hollow_inclusions_list = []\n",
    "percent_solid_inclusions_list = []\n",
    "percent_swiss_cheese_inclusions_list = []\n",
    "num_hollow_inclusions_list = []\n",
    "ave_child_inclusion_size_all = []\n",
    "num_swiss_cheese_list = []\n",
    "num_solid_list = []\n",
    "SA_lipids_list = []\n",
    "SA_inclusions_list = []\n",
    "for path in images_to_analyze:\n",
    "    print(path)\n",
    "    # Read the CZI file\n",
    "    czi_path = 'test_images/' + path\n",
    "    czi_file = czifile.CziFile(czi_path)\n",
    "    czi_data = czi_file.asarray()\n",
    "    shape = czi_data.shape\n",
    "    image_squeezed = np.squeeze(czi_data)\n",
    "    shape = image_squeezed.shape\n",
    "    green_channel = image_squeezed[1,:,:]\n",
    "    confocal_img = exposure.adjust_sigmoid(green_channel, cutoff=0.4)\n",
    "    # ---- segmentation\n",
    "    confocal_img = (confocal_img - confocal_img.min()) / (confocal_img.max() - confocal_img.min())\n",
    "    threshold_value = 0.06 # adjust this value as needed\n",
    "    binary_image_inclusions = confocal_img > threshold_value\n",
    "    plt.axis('off')\n",
    "    plt.imshow(binary_image_inclusions, cmap='gray')\n",
    "    plt.savefig(path + \"_new.png\", transparent=True, dpi = \"figure\", bbox_inches='tight', pad_inches=0)\n",
    "    # Label the objects: Use connected component analysis to label the segmented inclusions. \n",
    "    labeled_image_inclusions = label(binary_image_inclusions)\n",
    "    props_count_inclusions = regionprops(labeled_image_inclusions, confocal_img)\n",
    "    count_inclusions = len(props_count_inclusions)\n",
    "    sizes_inclusions = []\n",
    "    for prop in props_count_inclusions:\n",
    "        sizes_inclusions.append(prop.area)\n",
    "    inclusion_mask = path + \"_new.png\"\n",
    "    # Example usage\n",
    "    all_child_contour_areas, total_inclusions, num_hollow_inclusions, percentage_solid, percentage_hollow = quantify_inclusion_structure(inclusion_mask)\n",
    "    ave_child_inclusion_size_all.append(all_child_contour_areas)\n",
    "\n",
    "    # --------------- RED CHANNEL -----------------------------\n",
    "    red_channel = image_squeezed[0,:,:]\n",
    "    confocal_img = exposure.adjust_sigmoid(red_channel, cutoff=0.4)\n",
    "    # ---- segmentation\n",
    "    confocal_img = (confocal_img - confocal_img.min()) / (confocal_img.max() - confocal_img.min())\n",
    "    # threshold the image\n",
    "    threshold_value = 0.06 # adjust this value as needed\n",
    "    binary_image_lipids = confocal_img > threshold_value\n",
    "    # Label the objects: Use connected component analysis to label the segmented inclusions. \n",
    "    labeled_image_lipids = label(binary_image_lipids)\n",
    "    props_lipids = regionprops(labeled_image_lipids, confocal_img)\n",
    "    sizes_lipids = []\n",
    "    save_props_hollow = []\n",
    "    for prop in props_lipids:\n",
    "        sizes_lipids.append(prop.area)\n",
    "    # Get the region properties table as a dictionary\n",
    "    table = measure.regionprops_table(labeled_image_lipids, confocal_img, properties=('label', 'area', 'perimeter', 'major_axis_length', 'minor_axis_length'))\n",
    "    # Calculate the circularity index for each region\n",
    "    circularity_index = 4 * np.pi * table['area'] / ((table['perimeter'])**2)\n",
    "    # Define the size and circularity index thresholds\n",
    "    min_size = 700\n",
    "    min_circularity = 0.65\n",
    "    # Filter the labels that satisfy the thresholds\n",
    "    input_labels = table['label']\n",
    "    output_labels = input_labels * (table['area'] >= min_size) * (circularity_index >= min_circularity)\n",
    "    # Remap the label image using the filtered labels\n",
    "    mask = util.map_array(labeled_image_lipids, input_labels, output_labels)\n",
    "    # Define the size and circularity index thresholds\n",
    "    min_size = 20\n",
    "    max_circularity = 0.65\n",
    "    # Filter the labels that satisfy the thresholds\n",
    "    input_labels = table['label']\n",
    "    output_labels = input_labels * (table['area'] >= min_size) * (circularity_index < max_circularity)\n",
    "    # Remap the label image using the filtered labels\n",
    "    mask_swiss_cheese = util.map_array(labeled_image_lipids, input_labels, output_labels)\n",
    "    intersection_mask_swiss_cheese = mask_swiss_cheese.astype(bool) & binary_image_inclusions\n",
    "    radius = 9 # Adjust this value based on your requirement \n",
    "    selem = disk(radius)\n",
    "    binary_image_lipids_dilate = binary_dilation(intersection_mask_swiss_cheese, selem)\n",
    "    labeled_lipids_swiss_cheese = label(intersection_mask_swiss_cheese)\n",
    "    props_swiss_cheese = regionprops(labeled_lipids_swiss_cheese)\n",
    "    radius = 1.1 # Adjust this value based on your requirement\n",
    "    selem = disk(radius)\n",
    "    binary_image_lipids_dilate = binary_dilation(mask, selem)\n",
    "    intersection_mask = binary_image_lipids_dilate & binary_image_inclusions\n",
    "    labeled_lipids_hollow = label(intersection_mask)\n",
    "    props = regionprops(labeled_lipids_hollow)\n",
    "    total_hollow_inclusions = len(props)\n",
    "    num_swiss_cheese_list.append(len(props_swiss_cheese))\n",
    "    inclusions_solid_mask = binary_image_inclusions & ~binary_image_lipids_dilate & ~mask_swiss_cheese\n",
    "    labeled_inclusions_solid = label(inclusions_solid_mask)\n",
    "    props = regionprops(labeled_inclusions_solid)\n",
    "    total_solid_inclusions = 0\n",
    "    for prop in props:\n",
    "        if(prop.area >= 10):\n",
    "            total_solid_inclusions = total_solid_inclusions + 1\n",
    "    num_solid_list.append(total_solid_inclusions)\n",
    "    total_inclusions = total_hollow_inclusions + total_solid_inclusions + len(props_swiss_cheese)\n",
    "    number_of_inclusions_list.append(total_inclusions)\n",
    "\n",
    "    # --------------- BLUE CHANNEL -----------------------------\n",
    "\n",
    "    blue_channel = image_squeezed[2,:,:]\n",
    "    blurred_dapi = gaussian(blue_channel, sigma=2)\n",
    "    # Threshold the image: Use an appropriate thresholding method to segment the nuclei from the background. \n",
    "    threshold_value = threshold_otsu(blurred_dapi)\n",
    "    binary_image = blurred_dapi > threshold_value\n",
    "    # Clean up the segmentation: Use morphology operations to remove small objects and fill in any holes in the nuclei. \n",
    "    filled_image = morphology.remove_small_holes(binary_image, area_threshold=50000)\n",
    "    # Remove objects with less than 100 pixels\n",
    "    min_size = 400\n",
    "    cleaned_image = remove_small_objects(filled_image, min_size=min_size) \n",
    "    # assume 'binary_image' is the binary image containing the segmented nuclei\n",
    "    # set the size of the dilation element\n",
    "    selem = disk(5)\n",
    "    # dilate the binary image to merge adjacent objects\n",
    "    merged_image = binary_dilation(cleaned_image, footprint=selem)\n",
    "    # Label the objects: Use connected component analysis to label the segmented nuclei. \n",
    "    labeled_image_nuclei = label(merged_image)\n",
    "    # Count the number of objects: Count the number of unique labels in the labeled image. \n",
    "    n_objects = len(np.unique(labeled_image_nuclei)) - 1  # exclude background label 0\n",
    "    number_of_nuclei_list.append(n_objects)\n",
    "    # show segmented image \n",
    "    intersection_mask_lipids_inclusions = np.logical_and(binary_image_inclusions, binary_image_lipids)\n",
    "    props = regionprops(intersection_mask_lipids_inclusions.astype(np.uint8))\n",
    "    prop_sizes = []\n",
    "    for prop in props:\n",
    "        prop_sizes.append(prop.area)\n",
    "    total_area_intersection = np.sum(prop_sizes)\n",
    "    total_area_lipids = np.sum(sizes_lipids)\n",
    "    total_area_inclusions = np.sum(sizes_inclusions)\n",
    "    percent_SA_lipids = (total_area_intersection/total_area_lipids)*100\n",
    "    SA_lipids_list.append(total_area_lipids)\n",
    "    percent_SA_lipids_inclusions = (total_area_intersection/total_area_inclusions)*100\n",
    "    SA_inclusions_list.append(total_area_inclusions)\n",
    "    percent_SA_lipids_list.append(round(percent_SA_lipids,2))\n",
    "    percent_SA_lipids_list_inclusions.append(round(percent_SA_lipids_inclusions,2))\n",
    "    num_hollow_inclusions_list.append(total_hollow_inclusions)\n",
    "    percentage_hollow = total_hollow_inclusions/(total_hollow_inclusions + total_solid_inclusions + len(props_swiss_cheese))*100\n",
    "    percent_hollow_inclusions_list.append(round(percentage_hollow,2))\n",
    "    percentage_solid = total_solid_inclusions/(total_hollow_inclusions + total_solid_inclusions + len(props_swiss_cheese))*100\n",
    "    percent_solid_inclusions_list.append(round(percentage_solid,2))\n",
    "    percentage_swiss_cheese = len(props_swiss_cheese)/(total_hollow_inclusions + total_solid_inclusions + len(props_swiss_cheese))*100\n",
    "    percent_swiss_cheese_inclusions_list.append(round(percentage_swiss_cheese,2))\n",
    "\n",
    "df = pd.DataFrame(np.array(images_to_analyze).flatten())\n",
    "df.rename(columns={0: 'image'}, inplace=True)\n",
    "df.insert(1, \"number_of_nuclei\", np.array(number_of_nuclei_list).flatten(), True)\n",
    "df.insert(2, \"number_of_inclusions\", np.array(number_of_inclusions_list).flatten(), True)\n",
    "df.insert(3, \"percent_SA_lipids_overlap_lip\", np.array(percent_SA_lipids_list).flatten(), True)\n",
    "df.insert(4, \"percent_SA_lipids_overlap_inc\", np.array(percent_SA_lipids_list_inclusions).flatten(), True)\n",
    "df.insert(5, \"SA_lipids\", np.array(SA_lipids_list).flatten(), True)\n",
    "df.insert(6, \"SA_inclusions\", np.array(SA_inclusions_list).flatten(), True)\n",
    "df.insert(7, \"num_swiss_cheese_inclusions\", np.array(num_swiss_cheese_list).flatten(), True)\n",
    "df.insert(8, \"num_hollow_inclusions\", np.array(num_hollow_inclusions_list).flatten(), True)\n",
    "df.insert(9, \"num_solid_inclusions\", np.array(num_solid_list).flatten(), True)\n",
    "df.insert(10, \"percent_hollow_inclusions\", np.array(percent_hollow_inclusions_list).flatten(), True)\n",
    "df.insert(11, \"percent_swiss_cheese_inclusions\", np.array(percent_swiss_cheese_inclusions_list).flatten(), True)\n",
    "df.insert(12, \"percent_solid_inclusions\", np.array(percent_solid_inclusions_list).flatten(), True)\n",
    "df.to_excel(\"SUMMARY.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
