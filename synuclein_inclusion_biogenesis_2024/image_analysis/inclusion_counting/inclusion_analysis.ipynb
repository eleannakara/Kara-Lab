{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c492a815",
   "metadata": {},
   "source": [
    "The purpose of this code is to count inclusion number and size for various cell samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a449c9a",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed564c-a5f7-4ed5-bb0e-8ee097e40132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "from skimage import io, filters, morphology, segmentation, exposure\n",
    "from skimage.filters import gaussian, threshold_otsu, try_all_threshold\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import remove_small_objects, binary_dilation, disk\n",
    "import imageio\n",
    "from czifile import CziFile\n",
    "import czifile\n",
    "from cellpose import models\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340420f2",
   "metadata": {},
   "source": [
    "Define Sub Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration_cycle(image_analysis, basename):\n",
    "    individual_inclusions_per_cell = []\n",
    "    cell_inclusion_details = []  # To store cell number and inclusion count\n",
    "    model = models.Cellpose(gpu=False, model_type='cyto')  # Set gpu=True if you want to use GPU\n",
    "\n",
    "    image = czifile.imread(image_analysis)\n",
    "    image_squeezed = np.squeeze(image)\n",
    "    first_frame = image_squeezed[1, :, :]\n",
    "    target_shape = first_frame.shape\n",
    "    \n",
    "    blurred_frame = gaussian(first_frame, sigma=1)\n",
    "    normalized_image = (blurred_frame - blurred_frame.min()) / (blurred_frame.max() - blurred_frame.min())\n",
    "    # Replace NaN values with zero\n",
    "    normalized_image = np.nan_to_num(normalized_image)\n",
    "    plt.figure(figsize=(6, 6))  # Adjust figsize as needed\n",
    "    plt.imshow(first_frame, cmap='viridis')\n",
    "    plt.axis('off')  # Turn off axes\n",
    "\n",
    "    # Use Cellpose for cell segmentation\n",
    "    masks, flows, styles, diams = model.eval(normalized_image, diameter=None, channels=[0, 0])\n",
    "\n",
    "    labeled_image = label(masks)\n",
    "    props = regionprops(labeled_image)\n",
    "    for i, prop in enumerate(props):\n",
    "        if prop.area > 1000:\n",
    "            # Store the area of the cell\n",
    "            mask = labeled_image == prop.label  # Corrected to use prop.label\n",
    "            mask = zoom(mask, zoom=np.array(target_shape) / np.array(mask.shape), order=0)\n",
    "            mask_applied = mask * first_frame\n",
    "\n",
    "            mask_applied = gaussian(mask_applied)\n",
    "            \n",
    "            threshold_mean = (mask_applied - mask_applied.min()) / (mask_applied.max() - mask_applied.min())\n",
    "            threshold = threshold_otsu(threshold_mean[mask > 0]) + 0.15\n",
    "            inclusion_mask = mask_applied > threshold\n",
    "\n",
    "            labeled_inclusions = label(inclusion_mask)\n",
    "            inclusion_size = []\n",
    "            \n",
    "            for region in regionprops(labeled_inclusions):  # Loop through each inclusion\n",
    "                inclusion_size.append(region.area)\n",
    "        \n",
    "            for size in inclusion_size: \n",
    "                if size / prop.area > 0.7: # Catch cases of poor segmentation\n",
    "                    continue\n",
    "                individual_inclusions_per_cell.append({\n",
    "                    'Filename': basename,\n",
    "                    'Cell Number': i + 1,\n",
    "                    'Inclusion Size': size\n",
    "                })\n",
    "            cell_inclusion_details.append({\n",
    "                'Filename': basename,\n",
    "                'Cell Number': i + 1,\n",
    "                'Number of Inclusions': len(inclusion_size)\n",
    "            })\n",
    "                \n",
    "    df_individual = pd.DataFrame(individual_inclusions_per_cell)\n",
    "    df_cell_summary = pd.DataFrame(cell_inclusion_details)\n",
    "\n",
    "    return df_individual, df_cell_summary\n",
    "\n",
    "def sizes_of_all_inclusions(inclusions_size_list): \n",
    "    inclusions_df_array = []\n",
    "    for df in inclusions_size_list:\n",
    "        inclusions_df_array.extend(df.to_dict(orient='records'))\n",
    "    return pd.DataFrame(inclusions_df_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6408a",
   "metadata": {},
   "source": [
    "Define Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ac53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path\n",
    "image_dir = r\"test_images\"\n",
    "output_dir = os.getcwd()\n",
    "\n",
    "# List all files in the image directory\n",
    "images_to_analyze = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "\n",
    "inclusions_size_list = []\n",
    "df_cell_summary_list = []\n",
    "\n",
    "# Iterate through the list of image files\n",
    "for path in images_to_analyze:\n",
    "    if path.endswith('.czi'):\n",
    "        image_path = os.path.join(image_dir, path)\n",
    "        basename = os.path.basename(path)[:-4]\n",
    "        # Run the iteration cycle\n",
    "        df_individual, df_cell_summary = iteration_cycle(image_path, basename)\n",
    "        # Append the DataFrames to the respective lists\n",
    "        inclusions_size_list.append(df_individual)\n",
    "        df_cell_summary_list.append(df_cell_summary)\n",
    "\n",
    "# Combine all individual DataFrames\n",
    "combined_inclusions_df = sizes_of_all_inclusions(inclusions_size_list)\n",
    "# Save the combined DataFrame to an Excel file\n",
    "output_excel_path = os.path.join(output_dir, 'INCLUSION_SIZE.xlsx')\n",
    "combined_inclusions_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "# combine and save the cell summary DataFrames\n",
    "combined_cell_summary_df = pd.concat(df_cell_summary_list, ignore_index=True)\n",
    "output_summary_path = os.path.join(output_dir, 'SUMMARY.xlsx')\n",
    "combined_cell_summary_df.to_excel(output_summary_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
