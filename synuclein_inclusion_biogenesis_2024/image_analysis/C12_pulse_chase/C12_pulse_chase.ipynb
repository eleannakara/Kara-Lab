{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import gaussian, threshold_otsu, threshold_multiotsu\n",
    "from skimage.morphology import remove_small_objects, disk, binary_closing\n",
    "from scipy.ndimage import zoom, binary_dilation\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import io, exposure\n",
    "from skimage import measure\n",
    "from skimage import exposure\n",
    "from czifile import imread\n",
    "from cellpose import models, plot \n",
    "import re\n",
    "model_cellpose = models.Cellpose(model_type='cyto')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Sub Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, path, type):\n",
    "    \"\"\"Display the image.\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{path} {type}\")\n",
    "    plt.show()\n",
    "    \n",
    "def display_two_images(image1, image2, title1, title2, path):\n",
    "    \"\"\"Display two images side-by-side with smaller title font.\"\"\"\n",
    "    filename = os.path.basename(path)  # Extract final part of path\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    axes[0].imshow(image1, cmap='gray' if image1.ndim == 2 else None)\n",
    "    axes[0].set_title(f\"{filename} {title1}\", fontsize=10)\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(image2, cmap='gray' if image2.ndim == 2 else None)\n",
    "    axes[1].set_title(f\"{filename} {title2}\", fontsize=10)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def extract_image_paths(folder):\n",
    "    \"\"\"Extract all image file paths from the specified folder.\"\"\"\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"Read the LSM image from the specified path.\"\"\"\n",
    "    return imread(image_path)\n",
    "\n",
    "def size_threshold(image):\n",
    "    \"\"\"Remove small objects from the image.\"\"\"\n",
    "    return remove_small_objects(image, min_size=30)\n",
    "\n",
    "\n",
    "def extract_channels(image):\n",
    "    return image[0], image[1], image[2]\n",
    "\n",
    "def analyze_image_c12(c12):\n",
    "    contrast_adjusted_c12_normalized = (c12 - c12.min()) / (c12.max() - c12.min())\n",
    "    threshold_value_c12 = np.mean(contrast_adjusted_c12_normalized) + (np.std(contrast_adjusted_c12_normalized) * 2) #1.75 works well\n",
    "    c12_thresholded = contrast_adjusted_c12_normalized > threshold_value_c12\n",
    "    c12_thresholded = remove_small_objects(c12_thresholded, min_size=10)\n",
    "    labled_image = label(c12_thresholded)\n",
    "    return c12_thresholded\n",
    "\n",
    "def analyze_image_deep_red(deep_red):\n",
    "    contrast_adjusted_deep_red_normalized = (deep_red - deep_red.min()) / (deep_red.max() - deep_red.min())\n",
    "    threshold_value_deep_red = np.mean(contrast_adjusted_deep_red_normalized) + (np.std(contrast_adjusted_deep_red_normalized) * 3) #1.75 works well\n",
    "    deep_red_thresholded = contrast_adjusted_deep_red_normalized > threshold_value_deep_red\n",
    "    deep_red_thresholded = remove_small_objects(deep_red_thresholded, min_size=10)\n",
    "    labled_image = label(deep_red_thresholded)\n",
    "    return deep_red_thresholded\n",
    "\n",
    "def separate_touching_objects(deep_red_mask, c12_mask, verbose=False):\n",
    "    deep_red_only = np.zeros_like(deep_red_mask, dtype=np.uint8)\n",
    "    c12_only = np.zeros_like(c12_mask, dtype=np.uint8)\n",
    "\n",
    "    labeled_red = label(deep_red_mask)\n",
    "    labeled_c12 = label(c12_mask)\n",
    "\n",
    "    # Create full mask maps for checking overlap\n",
    "    red_object_map = labeled_red > 0\n",
    "    c12_object_map = labeled_c12 > 0\n",
    "\n",
    "    # Track red objects that do NOT overlap any c12\n",
    "    for region in regionprops(labeled_red):\n",
    "        mask = labeled_red == region.label\n",
    "        if np.any(mask & c12_object_map):\n",
    "            continue\n",
    "        else:\n",
    "            deep_red_only += mask\n",
    "\n",
    "    # Track c12 objects that do NOT overlap any deep red\n",
    "    for region in regionprops(labeled_c12):\n",
    "        mask = labeled_c12 == region.label\n",
    "        if np.any(mask & red_object_map):\n",
    "            continue\n",
    "        else:\n",
    "            c12_only += mask\n",
    "\n",
    "    return deep_red_only, c12_only\n",
    "def preprocess_green_channel(green_channel):\n",
    "    \"\"\"\n",
    "    Preprocess the green fluorescence channel for better segmentation and inclusion detection.\n",
    "    - Applies Gaussian blur to reduce noise.\n",
    "    - Enhances contrast using sigmoid adjustment.\n",
    "    - Normalizes intensities to [0, 1] for consistent processing.\n",
    "    \"\"\"\n",
    "    confocal_img = gaussian(green_channel, sigma=2)\n",
    "    confocal_img = exposure.adjust_sigmoid(green_channel, cutoff=0.25)\n",
    "    confocal_img = normalize_image(confocal_img)\n",
    "    return confocal_img\n",
    "\n",
    "def calculate_surface_area(labeled_image):\n",
    "    \"\"\"Calculate the total surface area for labeled regions.\"\"\"\n",
    "    props = regionprops(labeled_image)\n",
    "    return sum(prop.area for prop in props)\n",
    "\n",
    "\n",
    "def circularity_index(mask):\n",
    "    regions = measure.regionprops(label(mask))\n",
    "\n",
    "    # Create empty masks to store the results\n",
    "    clustered_lds = np.zeros_like(mask, dtype=bool)\n",
    "    single_lds = np.zeros_like(mask, dtype=bool)\n",
    "\n",
    "    # Iterate through regions and calculate circularity\n",
    "    for region in regions:\n",
    "        area = region.area\n",
    "        perimeter = measure.perimeter(region.image)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if perimeter == 0 or area <= 10:\n",
    "            continue\n",
    "        \n",
    "        circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "        \n",
    "        # Assign region to the appropriate mask based on circularity\n",
    "        if circularity < 0.8:\n",
    "            # Mask for clustered regions\n",
    "            clustered_lds[region.coords[:, 0], region.coords[:, 1]] = 1\n",
    "        else:\n",
    "            # Mask for non-clustered regions\n",
    "            single_lds[region.coords[:, 0], region.coords[:, 1]] = 1\n",
    "    \n",
    "    clustered_lds = clustered_lds.astype(bool)\n",
    "    single_lds = single_lds.astype(bool)\n",
    "\n",
    "    return clustered_lds, single_lds\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize the image to the range [0, 1].\n",
    "    This is useful for consistent processing across different images.\n",
    "    \"\"\"\n",
    "    return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "\n",
    "def segment_cells(green_channel):\n",
    "    \"\"\"\n",
    "    Segment whole cells in the green channel using Cellpose.\n",
    "    - Normalizes image intensity.\n",
    "    - Suppresses bright spots (e.g., inclusions) to better detect cell boundaries.\n",
    "    - Applies Gaussian blur for smoother segmentation input.\n",
    "    - Gradually increases segmentation diameter until at least one cell is detected.\n",
    "    \"\"\"\n",
    "    green_channel = normalize_image(green_channel)\n",
    "    percentile_99 = np.percentile(green_channel, 99)\n",
    "    \n",
    "    # Suppress very bright pixels (inclusions)\n",
    "    green_channel_remove_inclusions = np.where(green_channel < percentile_99, green_channel, percentile_99)\n",
    "    green_channel_remove_inclusions = gaussian(green_channel_remove_inclusions, sigma=5)\n",
    "\n",
    "    # Normalize again after processing\n",
    "    green_channel_remove_inclusions = normalize_image(green_channel_remove_inclusions)\n",
    "\n",
    "    # Try different diameters until cells are detected\n",
    "    diameter = 150\n",
    "    while diameter < 500:\n",
    "        masks, flows, styles, diams = model_cellpose.eval(green_channel_remove_inclusions, diameter=diameter, channels=[0, 0])\n",
    "        labeled_cells = label(masks)\n",
    "        if np.max(labeled_cells) > 0:\n",
    "            return labeled_cells\n",
    "        diameter += 25\n",
    "\n",
    "    # No cells found\n",
    "    return None\n",
    "\n",
    "def find_surface_area(mask, path, i, inclusion_mask, type, category) -> int:\n",
    "    if np.any(mask):\n",
    "        mask = label(mask)\n",
    "        surface_area = calculate_surface_area(mask)\n",
    "        #display_image(mask, path, i+1)\n",
    "        #print(f\"Cell {i + 1} has a {surface_area} surface area of {type} {category}\")\n",
    "        #display_image(inclusion_mask, path, i+1)\n",
    "        #print(f\"Inclusion image of cell {i + 1} above\")\n",
    "    else:\n",
    "        surface_area = 0\n",
    "    return surface_area\n",
    "\n",
    "\n",
    "\n",
    "def find_total_lds_and_surface_area(mask, path, i, type, category) -> int:\n",
    "    if np.any(mask):\n",
    "        mask_labeled = label(mask)\n",
    "        surface_area = calculate_surface_area(mask_labeled)\n",
    "        number_of_LDS = len(regionprops(mask_labeled))\n",
    "        #display_image(mask_labeled, path, i+1)\n",
    "        #print(f\"Cell {i + 1} has {type} {number_of_LDS} {category}\")\n",
    "    else:\n",
    "        surface_area = 0\n",
    "        number_of_LDS = 0\n",
    "    return surface_area, number_of_LDS\n",
    "\n",
    "def seperate_LDS(inclusion_image, LDS_mask):\n",
    "    LDS_in_inclusions = np.zeros_like(LDS_mask)\n",
    "    LDS_in_cyto = np.zeros_like(LDS_mask)\n",
    "\n",
    "    labled_LDS = label(LDS_mask)\n",
    "    for i, region in enumerate(regionprops(labled_LDS)):\n",
    "        mask = labled_LDS == region.label\n",
    "        overlap = mask * inclusion_image\n",
    "        if np.sum(overlap) > 0:\n",
    "            LDS_in_inclusions += mask\n",
    "        else:\n",
    "            LDS_in_cyto += mask\n",
    "    return LDS_in_inclusions, LDS_in_cyto\n",
    "\n",
    "def find_all_data(applied_mask, total_mask, clustered_mask, single_mask, inclusions, path, i, category) -> int:\n",
    "    LDS_in_cell = (applied_mask & total_mask)\n",
    "    clustered_LDS_in_cell = (applied_mask & clustered_mask)\n",
    "    single_LDS_in_cell = (applied_mask & single_mask)\n",
    "    surface_area_LDS, number_of_LDS = find_total_lds_and_surface_area(LDS_in_cell, path, i, \"total LDS\", category) \n",
    "    surface_area_clustered_LDS, number_of_clustered_LDS = find_total_lds_and_surface_area(clustered_LDS_in_cell, path, i, \"clustered LDS\", category)  \n",
    "    surface_area_single_LDS, number_of_single_LDS = find_total_lds_and_surface_area(single_LDS_in_cell, path, i, \"single LDS\", category)\n",
    "        \n",
    "    LDS_in_inclusion, LDS_not_in_inclusion = seperate_LDS(inclusions, LDS_in_cell)\n",
    "\n",
    "    surface_area_LDS_in_inclusion, number_of_LDS_in_inclusion = find_total_lds_and_surface_area(LDS_in_inclusion, path, i, \"LDS in inclusion\", category)\n",
    "    surface_area_LDS_not_in_inclusion, number_of_LDS_not_in_inclusion = find_total_lds_and_surface_area(LDS_not_in_inclusion, path, i, \"LDS not in inclusion\", category)\n",
    "\n",
    "    total_clustered_LDS_in_inclusion, total_clustered_LDS_not_in_inclusion = seperate_LDS(inclusions, clustered_LDS_in_cell)\n",
    "\n",
    "    surface_area_clustered_LDS_in_inclusion, number_of_clustered_LDS_in_inclusion = find_total_lds_and_surface_area(total_clustered_LDS_in_inclusion, path, i, \"clustered LDS in inclusion\", category)\n",
    "    surface_area_clustered_LDS_not_in_inclusion, number_of_clustered_LDS_not_in_inclusion = find_total_lds_and_surface_area(total_clustered_LDS_not_in_inclusion, path, i, \"clustered LDS not in inclusion\", category)\n",
    "\n",
    "    total_single_LDS_in_inclusion, total_single_LDS_not_in_inclusion = seperate_LDS(inclusions, single_LDS_in_cell)\n",
    "\n",
    "    surface_area_single_LDS_in_inclusion, number_of_single_LDS_in_inclusion = find_total_lds_and_surface_area(total_single_LDS_in_inclusion, path, i, \"single LDS in inclusion\", category)\n",
    "    surface_area_single_LDS_not_in_inclusion, number_of_single_LDS_not_in_inclusion = find_total_lds_and_surface_area(total_single_LDS_not_in_inclusion, path, i, \"single LDS not in inclusion\", category)\n",
    "\n",
    "\n",
    "    return surface_area_LDS, number_of_LDS, surface_area_clustered_LDS, number_of_clustered_LDS, surface_area_single_LDS, number_of_single_LDS, surface_area_LDS_in_inclusion, surface_area_LDS_not_in_inclusion, surface_area_clustered_LDS_in_inclusion, surface_area_clustered_LDS_not_in_inclusion, surface_area_single_LDS_in_inclusion, surface_area_single_LDS_not_in_inclusion, number_of_LDS_in_inclusion, number_of_LDS_not_in_inclusion, number_of_clustered_LDS_in_inclusion, number_of_clustered_LDS_not_in_inclusion, number_of_single_LDS_in_inclusion, number_of_single_LDS_not_in_inclusion\n",
    "\n",
    "def analysis(labeled_cells, path, red_total, c12_total, red_only, c12_only, inclusions_mask):\n",
    "    \n",
    "    cell_data = []\n",
    "\n",
    "    filtered_cells = [cell for cell in regionprops(labeled_cells) if cell.area >= 50]\n",
    "\n",
    "    clustered_c12_total, single_c12_total = circularity_index(c12_total)\n",
    "    clustered_red_total, single_red_total = circularity_index(red_total)\n",
    "    clustered_c12_only, single_c12_only = circularity_index(c12_only)\n",
    "    clustered_red_only, single_red_only = circularity_index(red_only)\n",
    "\n",
    "    for i, cell in enumerate(filtered_cells):\n",
    "        mask = labeled_cells == cell.label\n",
    "        \n",
    "\n",
    "\n",
    "        inclusion_size = []\n",
    "        inclusion_size_swiss = []\n",
    "        inclusion_size_solid = []\n",
    "\n",
    "        \n",
    "        applied_mask = mask > 0  # Convert to boolean if not already\n",
    "        red_total = red_total > 0  # Convert to boolean if not already\n",
    "        c12_total = c12_total > 0  # Convert to boolean if not already\n",
    "        red_only = red_only > 0  # Convert to boolean if not already\n",
    "        c12_only = c12_only > 0  # Convert to boolean if not already\n",
    "        inclusions_in_cell = inclusions_mask * mask\n",
    "        inclusions_in_cell_labeled = label(inclusions_in_cell)\n",
    "\n",
    "        \n",
    "        total_surface_area_C12_LDS, total_C12_LDS, total_surface_area_clustered_C12_LDS, total_clustered_C12_LDS, total_surface_area_single_C12_LDS, total_single_C12_LDS, surface_area_C12_total_LDS_in_inclusion, surface_area_C12_total_LDS_not_in_inclusion, surface_area_clustered_C12_LDS_in_inclusion, surface_area_clustered_C12_LDS_not_in_inclusion, surface_area_single_C12_LDS_in_inclusion, surface_area_single_C12_LDS_not_in_inclusion, number_of_LDS_in_inclusion_all_c12, number_of_LDS_not_in_inclusion_all_c12, number_of_clustered_LDS_in_inclusion_all_c12, number_of_clustered_LDS_not_in_inclusion_all_c12, number_of_single_LDS_in_inclusion_all_c12, number_of_single_LDS_not_in_inclusion_all_c12 = find_all_data(applied_mask, c12_total, clustered_c12_total, single_c12_total, inclusions_in_cell, path, i, \"total c12\")\n",
    "        \n",
    "        total_surface_area_red_LDS, total_red_LDS, total_surface_area_clustered_red_LDS, total_clustered_red_LDS, total_surface_area_single_red_LDS, total_single_red_LDS, surface_area_total_red_LDS_in_inclusion, surface_area_total_red_LDS_not_in_inclusion, surface_area_clustered_red_LDS_in_inclusion, surface_area_clustered_red_LDS_not_in_inclusion, surface_area_single_red_LDS_in_inclusion, surface_area_single_red_LDS_not_in_inclusion, number_of_LDS_in_inclusion_all_red, number_of_LDS_not_in_inclusion_all_red, number_of_clustered_LDS_in_inclusion_all_red, number_of_clustered_LDS_not_in_inclusion_all_red, number_of_single_LDS_in_inclusion_all_red, number_of_single_LDS_not_in_inclusion_all_red = find_all_data(applied_mask, red_total, clustered_red_total, single_red_total, inclusions_in_cell, path, i, \"total red\")\n",
    "\n",
    "        total_surface_area_red_LDS_only, total_red_LDS_only, total_surface_area_clustered_red_LDS_only, total_clustered_red_LDS_only, total_surface_area_single_red_LDS_only, total_single_red_LDS_only, surface_area_total_red_LDS_only_in_inclusion, surface_area_total_red_LDS_only_not_in_inclusion, surface_area_clustered_red_LDS_only_in_inclusion, surface_area_clustered_red_LDS_only_not_in_inclusion, surface_area_single_red_LDS_only_in_inclusion, surface_area_single_red_LDS_only_not_in_inclusion, number_of_LDS_in_inclusion_red_only, number_of_LDS_not_in_inclusion_red_only, number_of_clustered_LDS_in_inclusion_red_only, number_of_clustered_LDS_not_in_inclusion_red_only, number_of_single_LDS_in_inclusion_red_only, number_of_single_LDS_not_in_inclusion_red_only = find_all_data(applied_mask, red_only, clustered_red_only, single_red_only, inclusions_in_cell, path, i, \"red only\")\n",
    "\n",
    "        total_surface_area_C12_LDS_only, total_C12_LDS_only, total_surface_area_clustered_C12_LDS_only, total_clustered_C12_LDS_only, total_surface_area_single_C12_LDS_only, total_single_C12_LDS_only, surface_area_total_C12_LDS_only_in_inclusion, surface_area_total_C12_LDS_only_not_in_inclusion, surface_area_clustered_C12_LDS_only_in_inclusion, surface_area_clustered_C12_LDS_only_not_in_inclusion, surface_area_single_C12_LDS_only_in_inclusion, surface_area_single_C12_LDS_only_not_in_inclusion, number_of_LDS_in_inclusion_c12_only, number_of_LDS_not_in_inclusion_c12_only, number_of_clustered_LDS_in_inclusion_c12_only, number_of_clustered_LDS_not_in_inclusion_c12_only, number_of_single_LDS_in_inclusion_c12_only, number_of_single_LDS_not_in_inclusion_c12_only = find_all_data(applied_mask, c12_only, clustered_c12_only, single_c12_only, inclusions_in_cell, path, i, \"c12 only\")\n",
    "\n",
    "\n",
    "        for inclusion in regionprops(inclusions_in_cell_labeled):\n",
    "            if inclusion.area > 0:\n",
    "                inclusion_mask = inclusions_in_cell_labeled == inclusion.label\n",
    "                LDS_in_inclusion = (inclusion_mask & red_total) | (inclusion_mask & c12_total)\n",
    "                inclusion_size.append(inclusion.area)\n",
    "\n",
    "                # Determine inclusion type based on lipid presence\n",
    "                if np.any(LDS_in_inclusion):\n",
    "                    inclusion_size_swiss.append(inclusion.area)\n",
    "                    type = \"swiss\"\n",
    "                else:\n",
    "                    inclusion_size_solid.append(inclusion.area)\n",
    "                    type = \"solid\"\n",
    "                #print(f\"{inclusion.area} {type} inclusion in cell {cell.label}\")\n",
    "\n",
    "        if not inclusion_size:\n",
    "            cell_data.append({\n",
    "                'Filename': path,\n",
    "                'Cell Number': i + 1,\n",
    "                'Cytoplasm Surface Area': cell.area,\n",
    "                'Total Number of Inclusions': None,  # No inclusion number\n",
    "                'Average Surface Area of all Inclusions': 0,  # No inclusion surface area\n",
    "                'Number of Solid Inclusions': 0,\n",
    "                'Average Surface Area of Solid Inclusions': 0,  # Average surface area of solid inclusions\n",
    "                'Number of Swiss Inclusions': 0,\n",
    "                'Average Surface Area of Swiss Inclusions': 0,  # Surface area of this inclusion\n",
    "                'Number of all C12 Clumped LDS': total_clustered_C12_LDS,\n",
    "                'Surface area of all C12 Clumped LDS': total_surface_area_clustered_C12_LDS,\n",
    "                'Number of all C12 Clumped LDS in inclusion': number_of_clustered_LDS_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 Clumped LDS in inclusion': surface_area_clustered_C12_LDS_in_inclusion,\n",
    "                'Number of all C12 Clumped LDS not in inclusion': number_of_clustered_LDS_not_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 Clumped LDS not in inclusion': surface_area_clustered_C12_LDS_not_in_inclusion,\n",
    "                'Number of all C12 Single LDS': total_single_C12_LDS,\n",
    "                'Surface area of all C12 Single LDS': total_surface_area_single_C12_LDS,\n",
    "                'Number of all C12 Single LDS in inclusion': number_of_single_LDS_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 Single LDS in inclusion': surface_area_single_C12_LDS_in_inclusion,\n",
    "                'Number of all C12 Single LDS not in inclusion': number_of_single_LDS_not_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 Single LDS not in inclusion': surface_area_single_C12_LDS_not_in_inclusion,\n",
    "                'Number of all C12 total LDS': total_C12_LDS,\n",
    "                'Surface area of all C12 total LDS': total_surface_area_C12_LDS,\n",
    "                'Number of all C12 total LDS in inclusion': number_of_LDS_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 total LDS in inclusion': surface_area_C12_total_LDS_in_inclusion,\n",
    "                'Number of all C12 total LDS not in inclusion': number_of_LDS_not_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 total LDS not in inclusion': surface_area_C12_total_LDS_not_in_inclusion,\n",
    "                'Number of all Red Clumped LDS': total_clustered_red_LDS,\n",
    "                'Surface area of all Red Clumped LDS': total_surface_area_clustered_red_LDS,\n",
    "                'Number of all Red Clumped LDS in inclusion': number_of_clustered_LDS_in_inclusion_all_red,\n",
    "                'Surface area of all Red Clumped LDS in inclusion': surface_area_clustered_red_LDS_in_inclusion,\n",
    "                'Number of all Red Clumped LDS not in inclusion': number_of_clustered_LDS_not_in_inclusion_all_red,\n",
    "                'Surface area of all Red Clumped LDS not in inclusion': surface_area_clustered_red_LDS_not_in_inclusion,\n",
    "                'Number of all Red Single LDS': total_single_red_LDS,\n",
    "                'Surface area of all Red Single LDS': total_surface_area_single_red_LDS,\n",
    "                'Number of all Red Single LDS in inclusion': number_of_single_LDS_in_inclusion_all_red,\n",
    "                'Surface area of all Red Single LDS in inclusion': surface_area_single_red_LDS_in_inclusion,\n",
    "                'Number of all Red Single LDS not in inclusion': number_of_single_LDS_not_in_inclusion_all_red,\n",
    "                'Surface area of all Red Single LDS not in inclusion': surface_area_single_red_LDS_not_in_inclusion,\n",
    "                'Number of all Red Total LDS': total_red_LDS,\n",
    "                'Surface area of all Red Total LDS': total_surface_area_red_LDS,\n",
    "                'Number of all Red Total LDS in inclusion': number_of_LDS_in_inclusion_all_red,\n",
    "                'Surface area of all Red Total LDS in inclusion': surface_area_total_red_LDS_in_inclusion,\n",
    "                'Number of all Red Total LDS not in inclusion': number_of_LDS_not_in_inclusion_all_red,\n",
    "                'Surface area of all Red Total LDS not in inclusion': surface_area_total_red_LDS_not_in_inclusion,\n",
    "                'Number of C12-only clumped LDS': total_clustered_C12_LDS_only,\n",
    "                'Surface area of C12-only clumped LDS': total_surface_area_clustered_C12_LDS_only,\n",
    "                'Number of C12-only clumped LDS in inclusion': number_of_clustered_LDS_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only clumped LDS in inclusion': surface_area_clustered_C12_LDS_only_in_inclusion,\n",
    "                'Number of C12-only clumped LDS not in inclusion': number_of_clustered_LDS_not_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only clumped LDS not in inclusion': surface_area_clustered_C12_LDS_only_not_in_inclusion,\n",
    "                'Number of C12-only Single LDS': total_single_C12_LDS_only,\n",
    "                'Surface area of C12-only Single LDS': total_surface_area_single_C12_LDS_only,\n",
    "                'Number of C12-only Single LDS in inclusion': number_of_single_LDS_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only Single LDS in inclusion': surface_area_single_C12_LDS_only_in_inclusion,\n",
    "                'Number of C12-only Single LDS not in inclusion': number_of_single_LDS_not_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only Single LDS not in inclusion': surface_area_single_C12_LDS_only_not_in_inclusion,\n",
    "                'Number of C12-only Total LDS': total_C12_LDS_only,\n",
    "                'Surface area of C12-only Total LDS': total_surface_area_C12_LDS_only,\n",
    "                'Number of C12-only Total LDS in inclusion': number_of_LDS_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only Total LDS in inclusion': surface_area_total_C12_LDS_only_in_inclusion,\n",
    "                'Number of C12-only Total LDS not in inclusion': number_of_LDS_not_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only Total LDS not in inclusion': surface_area_total_C12_LDS_only_not_in_inclusion,\n",
    "                'Number of Red-only Clumped LDS': total_clustered_red_LDS_only,\n",
    "                'Surface area of Red-only Clumped LDS': total_surface_area_clustered_red_LDS_only,\n",
    "                'Number of Red-only Clumped LDS in inclusion': number_of_clustered_LDS_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Clumped LDS in inclusion': surface_area_clustered_red_LDS_only_in_inclusion,\n",
    "                'Number of Red-only Clumped LDS not in inclusion': number_of_clustered_LDS_not_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Clumped LDS not in inclusion': surface_area_clustered_red_LDS_only_not_in_inclusion,\n",
    "                'Number of Red-only Single LDS': total_single_red_LDS_only,\n",
    "                'Surface area of Red-only Single LDS': total_surface_area_single_red_LDS_only,\n",
    "                'Number of Red-only Single LDS in inclusion': number_of_single_LDS_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Single LDS in inclusion': surface_area_single_red_LDS_only_in_inclusion,\n",
    "                'Number of Red-only Single LDS not in inclusion': number_of_single_LDS_not_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Single LDS not in inclusion': surface_area_single_red_LDS_only_not_in_inclusion,\n",
    "                'Number of Red-only Total LDS': total_red_LDS_only,\n",
    "                'Surface area of Red-only Total LDS': total_surface_area_red_LDS_only,\n",
    "                'Number of Red-only Total LDS in inclusion': number_of_LDS_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Total LDS in inclusion': surface_area_total_red_LDS_only_in_inclusion,\n",
    "                'Number of Red-only Total LDS not in inclusion': number_of_LDS_not_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Total LDS not in inclusion': surface_area_total_red_LDS_only_not_in_inclusion\n",
    "            })\n",
    "        else:\n",
    "            total_inclusions = len(inclusion_size)  # Total number of inclusions\n",
    "            average_surface_area = sum(inclusion_size) / total_inclusions  # Average surface area\n",
    "\n",
    "            number_of_solid_inclusions = len(inclusion_size_solid)  \n",
    "\n",
    "            if number_of_solid_inclusions == 0:\n",
    "                average_surface_area_solid = 0\n",
    "            else: \n",
    "                average_surface_area_solid = sum(inclusion_size_solid) / number_of_solid_inclusions\n",
    "\n",
    "            number_of_swiss_inclusions = len(inclusion_size_swiss) \n",
    "\n",
    "            if number_of_swiss_inclusions == 0:\n",
    "                average_surface_area_swiss = 0\n",
    "            else:\n",
    "                # Avoid division by zero for average surface area of swiss inclusions\n",
    "                average_surface_area_swiss = sum(inclusion_size_swiss) / number_of_swiss_inclusions\n",
    "\n",
    "            cell_data.append({\n",
    "                'Filename': path,\n",
    "                'Cell Number': i + 1,\n",
    "                'Cytoplasm Surface Area': cell.area,\n",
    "                'Total Number of Inclusions': total_inclusions, \n",
    "                'Average Surface Area of all Inclusions': average_surface_area,  # Average surface area of inclusions\n",
    "                'Number of Solid Inclusions': number_of_solid_inclusions,\n",
    "                'Average Surface Area of Solid Inclusions': average_surface_area_solid,  # Average surface area of solid inclusions\n",
    "                'Number of Swiss Inclusions': number_of_swiss_inclusions,\n",
    "                'Average Surface Area of Swiss Inclusions': average_surface_area_swiss,  # Surface area of this inclusion\n",
    "                'Number of all C12 Clumped LDS': total_clustered_C12_LDS,\n",
    "                'Surface area of all C12 Clumped LDS': total_surface_area_clustered_C12_LDS,\n",
    "                'Number of all C12 Clumped LDS in inclusion': number_of_clustered_LDS_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 Clumped LDS in inclusion': surface_area_clustered_C12_LDS_in_inclusion,\n",
    "                'Number of all C12 Clumped LDS not in inclusion': number_of_clustered_LDS_not_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 Clumped LDS not in inclusion': surface_area_clustered_C12_LDS_not_in_inclusion,\n",
    "                'Number of all C12 Single LDS': total_single_C12_LDS,\n",
    "                'Surface area of all C12 Single LDS': total_surface_area_single_C12_LDS,\n",
    "                'Number of all C12 Single LDS in inclusion': number_of_single_LDS_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 Single LDS in inclusion': surface_area_single_C12_LDS_in_inclusion,\n",
    "                'Number of all C12 Single LDS not in inclusion': number_of_single_LDS_not_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 Single LDS not in inclusion': surface_area_single_C12_LDS_not_in_inclusion,\n",
    "                'Number of all C12 total LDS': total_C12_LDS,\n",
    "                'Surface area of all C12 total LDS': total_surface_area_C12_LDS,\n",
    "                'Number of all C12 total LDS in inclusion': number_of_LDS_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 total LDS in inclusion': surface_area_C12_total_LDS_in_inclusion,\n",
    "                'Number of all C12 total LDS not in inclusion': number_of_LDS_not_in_inclusion_all_c12,\n",
    "                'Surface area of all C12 total LDS not in inclusion': surface_area_C12_total_LDS_not_in_inclusion,\n",
    "                'Number of all Red Clumped LDS': total_clustered_red_LDS,\n",
    "                'Surface area of all Red Clumped LDS': total_surface_area_clustered_red_LDS,\n",
    "                'Number of all Red Clumped LDS in inclusion': number_of_clustered_LDS_in_inclusion_all_red,\n",
    "                'Surface area of all Red Clumped LDS in inclusion': surface_area_clustered_red_LDS_in_inclusion,\n",
    "                'Number of all Red Clumped LDS not in inclusion': number_of_clustered_LDS_not_in_inclusion_all_red,\n",
    "                'Surface area of all Red Clumped LDS not in inclusion': surface_area_clustered_red_LDS_not_in_inclusion,\n",
    "                'Number of all Red Single LDS': total_single_red_LDS,\n",
    "                'Surface area of all Red Single LDS': total_surface_area_single_red_LDS,\n",
    "                'Number of all Red Single LDS in inclusion': number_of_single_LDS_in_inclusion_all_red,\n",
    "                'Surface area of all Red Single LDS in inclusion': surface_area_single_red_LDS_in_inclusion,\n",
    "                'Number of all Red Single LDS not in inclusion': number_of_single_LDS_not_in_inclusion_all_red,\n",
    "                'Surface area of all Red Single LDS not in inclusion': surface_area_single_red_LDS_not_in_inclusion,\n",
    "                'Number of all Red Total LDS': total_red_LDS,\n",
    "                'Surface area of all Red Total LDS': total_surface_area_red_LDS,\n",
    "                'Number of all Red Total LDS in inclusion': number_of_LDS_in_inclusion_all_red,\n",
    "                'Surface area of all Red Total LDS in inclusion': surface_area_total_red_LDS_in_inclusion,\n",
    "                'Number of all Red Total LDS not in inclusion': number_of_LDS_not_in_inclusion_all_red,\n",
    "                'Surface area of all Red Total LDS not in inclusion': surface_area_total_red_LDS_not_in_inclusion,\n",
    "                'Number of C12-only clumped LDS': total_clustered_C12_LDS_only,\n",
    "                'Surface area of C12-only clumped LDS': total_surface_area_clustered_C12_LDS_only,\n",
    "                'Number of C12-only clumped LDS in inclusion': number_of_clustered_LDS_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only clumped LDS in inclusion': surface_area_clustered_C12_LDS_only_in_inclusion,\n",
    "                'Number of C12-only clumped LDS not in inclusion': number_of_clustered_LDS_not_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only clumped LDS not in inclusion': surface_area_clustered_C12_LDS_only_not_in_inclusion,\n",
    "                'Number of C12-only Single LDS': total_single_C12_LDS_only,\n",
    "                'Surface area of C12-only Single LDS': total_surface_area_single_C12_LDS_only,\n",
    "                'Number of C12-only Single LDS in inclusion': number_of_single_LDS_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only Single LDS in inclusion': surface_area_single_C12_LDS_only_in_inclusion,\n",
    "                'Number of C12-only Single LDS not in inclusion': number_of_single_LDS_not_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only Single LDS not in inclusion': surface_area_single_C12_LDS_only_not_in_inclusion,\n",
    "                'Number of C12-only Total LDS': total_C12_LDS_only,\n",
    "                'Surface area of C12-only Total LDS': total_surface_area_C12_LDS_only,\n",
    "                'Number of C12-only Total LDS in inclusion': number_of_LDS_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only Total LDS in inclusion': surface_area_total_C12_LDS_only_in_inclusion,\n",
    "                'Number of C12-only Total LDS not in inclusion': number_of_LDS_not_in_inclusion_c12_only,\n",
    "                'Surface area of C12-only Total LDS not in inclusion': surface_area_total_C12_LDS_only_not_in_inclusion,\n",
    "                'Number of Red-only Clumped LDS': total_clustered_red_LDS_only,\n",
    "                'Surface area of Red-only Clumped LDS': total_surface_area_clustered_red_LDS_only,\n",
    "                'Number of Red-only Clumped LDS in inclusion': number_of_clustered_LDS_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Clumped LDS in inclusion': surface_area_clustered_red_LDS_only_in_inclusion,\n",
    "                'Number of Red-only Clumped LDS not in inclusion': number_of_clustered_LDS_not_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Clumped LDS not in inclusion': surface_area_clustered_red_LDS_only_not_in_inclusion,\n",
    "                'Number of Red-only Single LDS': total_single_red_LDS_only,\n",
    "                'Surface area of Red-only Single LDS': total_surface_area_single_red_LDS_only,\n",
    "                'Number of Red-only Single LDS in inclusion': number_of_single_LDS_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Single LDS in inclusion': surface_area_single_red_LDS_only_in_inclusion,\n",
    "                'Number of Red-only Single LDS not in inclusion': number_of_single_LDS_not_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Single LDS not in inclusion': surface_area_single_red_LDS_only_not_in_inclusion,\n",
    "                'Number of Red-only Total LDS': total_red_LDS_only,\n",
    "                'Surface area of Red-only Total LDS': total_surface_area_red_LDS_only,\n",
    "                'Number of Red-only Total LDS in inclusion': number_of_LDS_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Total LDS in inclusion': surface_area_total_red_LDS_only_in_inclusion,\n",
    "                'Number of Red-only Total LDS not in inclusion': number_of_LDS_not_in_inclusion_red_only,\n",
    "                'Surface area of Red-only Total LDS not in inclusion': surface_area_total_red_LDS_only_not_in_inclusion\n",
    "            })\n",
    "    df_cell_summary = pd.DataFrame(cell_data)\n",
    "\n",
    "    return df_cell_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class UNetPP(nn.Module):\n",
    "    def __init__(self, n_classes, in_channels=1, base_ch=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv00 = ConvBlock(in_channels, base_ch)\n",
    "        self.pool0 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv10 = ConvBlock(base_ch, base_ch * 2)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv20 = ConvBlock(base_ch * 2, base_ch * 4)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv30 = ConvBlock(base_ch * 4, base_ch * 8)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv40 = ConvBlock(base_ch * 8, base_ch * 16)\n",
    "\n",
    "        # Nested decoder\n",
    "        self.up01 = ConvBlock(base_ch + base_ch * 2, base_ch)\n",
    "        self.up11 = ConvBlock(base_ch * 2 + base_ch * 4, base_ch * 2)\n",
    "        self.up21 = ConvBlock(base_ch * 4 + base_ch * 8, base_ch * 4)\n",
    "        self.up31 = ConvBlock(base_ch * 8 + base_ch * 16, base_ch * 8)\n",
    "\n",
    "        self.up02 = ConvBlock(base_ch * 2 + base_ch, base_ch)\n",
    "        self.up12 = ConvBlock(base_ch * 4 + base_ch * 2, base_ch * 2)\n",
    "        self.up22 = ConvBlock(base_ch * 8 + base_ch * 4, base_ch * 4)\n",
    "\n",
    "        self.up03 = ConvBlock(base_ch * 2 + base_ch, base_ch)\n",
    "        self.up13 = ConvBlock(base_ch * 4 + base_ch * 2, base_ch * 2)\n",
    "\n",
    "        self.up04 = ConvBlock(base_ch * 2 + base_ch, base_ch)\n",
    "\n",
    "        self.final = nn.Conv2d(base_ch, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x00 = self.conv00(x)\n",
    "        x10 = self.conv10(self.pool0(x00))\n",
    "        x20 = self.conv20(self.pool1(x10))\n",
    "        x30 = self.conv30(self.pool2(x20))\n",
    "        x40 = self.conv40(self.pool3(x30))\n",
    "\n",
    "        x01 = self.up01(torch.cat([x00, F.interpolate(x10, x00.shape[2:])], dim=1))\n",
    "        x11 = self.up11(torch.cat([x10, F.interpolate(x20, x10.shape[2:])], dim=1))\n",
    "        x21 = self.up21(torch.cat([x20, F.interpolate(x30, x20.shape[2:])], dim=1))\n",
    "        x31 = self.up31(torch.cat([x30, F.interpolate(x40, x30.shape[2:])], dim=1))\n",
    "\n",
    "        x02 = self.up02(torch.cat([x01, F.interpolate(x11, x01.shape[2:])], dim=1))\n",
    "        x12 = self.up12(torch.cat([x11, F.interpolate(x21, x11.shape[2:])], dim=1))\n",
    "        x22 = self.up22(torch.cat([x21, F.interpolate(x31, x21.shape[2:])], dim=1))\n",
    "\n",
    "        x03 = self.up03(torch.cat([x02, F.interpolate(x12, x02.shape[2:])], dim=1))\n",
    "        x13 = self.up13(torch.cat([x12, F.interpolate(x22, x12.shape[2:])], dim=1))\n",
    "\n",
    "        x04 = self.up04(torch.cat([x03, F.interpolate(x13, x03.shape[2:])], dim=1))\n",
    "\n",
    "        return self.final(x04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetPP(\n",
       "  (conv00): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv10): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv20): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv30): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv40): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up01): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up11): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up21): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up31): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up02): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up12): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up22): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up03): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up13): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up04): ConvBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (final): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = hf_hub_download(repo_id=\"sunny17347/unet-model\", filename=\"unetpp_trained.pth\")\n",
    "\n",
    "model = UNetPP(n_classes=2)  # or whatever n_classes you trained with\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(image_folder):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    images_to_analyze = extract_image_paths(image_folder)\n",
    "    output_dir = os.getcwd()\n",
    "    df_cell_summary_list = []\n",
    "    # Iterate over each image\n",
    "    for path in images_to_analyze:\n",
    "        image = read_image(path)\n",
    "        image_squeezed = np.squeeze(image) \n",
    "        deep_red, c12, green_channel = extract_channels(image_squeezed)\n",
    "\n",
    "        preprocessed_green_channel = preprocess_green_channel(green_channel)\n",
    "\n",
    "        labeled_cells = segment_cells(preprocessed_green_channel)\n",
    "\n",
    "        \n",
    "        #display_two_images(green_channel, labeled_cells, path, \"green channel\", \"labeled cells\")\n",
    "\n",
    "        green_np_image = np.array(green_channel).astype(np.float32)\n",
    "        green_np_image /= 65535.0\n",
    "\n",
    "        green_np_image = exposure.adjust_gamma(green_np_image, gamma=0.75)\n",
    "\n",
    "        tensor = torch.from_numpy(green_np_image).unsqueeze(0)  # shape: (1, H, W)\n",
    "\n",
    "        input_tensor = tensor.unsqueeze(0).to(device)  # shape: (1, 1, H, W)\n",
    "\n",
    "            # Predict\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            pred = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "        inclusion_image = pred > 0  # Convert to boolean mask\n",
    "        #display_two_images(green_channel, inclusion_image, path, \"green channel\", \"inclusion mask\")\n",
    "\n",
    "        \n",
    "\n",
    "        c12_mask = analyze_image_c12(c12)\n",
    "        #display_two_images(c12, c12_mask, path, \"c12\", \"c12 mask\")\n",
    "        deep_red_mask = analyze_image_deep_red(deep_red)\n",
    "        #display_two_images(deep_red, deep_red_mask, path, \"deep red\", \"deep red mask\")\n",
    "\n",
    "        \n",
    "\n",
    "        deep_red_only_mask, c12_only_mask = separate_touching_objects(deep_red_mask, c12_mask, path)\n",
    "        #display_two_images(deep_red, deep_red_only_mask, path, \"deep red\", \"deep red only mask\")\n",
    "        #display_two_images(c12, c12_only_mask, path, \"c12\", \"c12 only mask\")\n",
    "\n",
    "\n",
    "\n",
    "        df_cell_summary = analysis(labeled_cells, path, deep_red_mask, c12_mask, deep_red_only_mask, c12_only_mask, inclusion_image)\n",
    "        df_cell_summary_list.append(df_cell_summary)\n",
    "        \n",
    "    combined_cell_summary_df = pd.concat(df_cell_summary_list, ignore_index=True)\n",
    "    output_summary_path = os.path.join(output_dir, '021925_SUMMARY.xlsx')\n",
    "    combined_cell_summary_df.to_excel(output_summary_path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_folder = '021925_images'\n",
    "    main(image_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
