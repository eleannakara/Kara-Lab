{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63226cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import gaussian, threshold_otsu, threshold_multiotsu, sobel\n",
    "from skimage.morphology import remove_small_objects, disk, binary_closing\n",
    "from scipy.ndimage import zoom, binary_dilation, binary_erosion, distance_transform_edt\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import io, exposure, color\n",
    "from skimage import measure, morphology\n",
    "from skimage import exposure\n",
    "from czifile import imread\n",
    "from cellpose import models, plot \n",
    "from matplotlib.ticker import MaxNLocator\n",
    "model = models.Cellpose(gpu=False, model_type='cyto3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b565c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_INCLUSION_SIZE = 10\n",
    "MAX_INCLUSION_SIZE = 2000\n",
    "RADIUS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924aaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, path, type):\n",
    "    \"\"\"Display the image.\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{path} {type}\")\n",
    "    plt.show()\n",
    "\n",
    "def get_filename_from_path(path):\n",
    "    \"\"\"Extracts the last part of the path after the final slash.\"\"\"\n",
    "    return os.path.basename(path)\n",
    "\n",
    "def display_two_images(image1, image2, title1, title2, path):\n",
    "    \"\"\"Display two images side-by-side with smaller title font.\"\"\"\n",
    "    filename = os.path.basename(path)  # Extract final part of path\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    axes[0].imshow(image1, cmap='gray' if image1.ndim == 2 else None)\n",
    "    axes[0].set_title(f\"{filename} {title1}\", fontsize=10)\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(image2, cmap='gray' if image2.ndim == 2 else None)\n",
    "    axes[1].set_title(f\"{filename} {title2}\", fontsize=10)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def extract_image_paths(folder):\n",
    "    \"\"\"Extract all image file paths from the specified folder.\"\"\"\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"Read the LSM image from the specified path.\"\"\"\n",
    "    return imread(image_path)\n",
    "\n",
    "def count(mask): \n",
    "    \"\"\"Count the number of unique labels in the mask.\"\"\"\n",
    "    return len(np.unique(label(mask))) - 1  # Exclude background label (0)\n",
    "\n",
    "def extract_channels(image: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Extract green and red channels from the squeezed image (shape: [Z, C, H, W]).\"\"\" \n",
    "    return image[0], image[1], image[2]  \n",
    "\n",
    "def preprocess_green_channel(green_channel):\n",
    "    \"\"\"\n",
    "    Preprocess the green fluorescence channel for better segmentation and inclusion detection.\n",
    "    - Applies Gaussian blur to reduce noise.\n",
    "    - Enhances contrast using sigmoid adjustment.\n",
    "    - Normalizes intensities to [0, 1] for consistent processing.\n",
    "    \"\"\"\n",
    "    confocal_img = gaussian(green_channel, sigma=2)\n",
    "    confocal_img = exposure.adjust_sigmoid(green_channel, cutoff=0.25)\n",
    "    confocal_img = normalize_image(confocal_img)\n",
    "    return confocal_img\n",
    "\n",
    "    return circular_mask, non_circular_mask\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize the image to the range [0, 1].\n",
    "    This is useful for consistent processing across different images.\n",
    "    \"\"\"\n",
    "    return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "\n",
    "def calculate_surface_area(labeled_image: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the total surface area for labeled regions.\"\"\"\n",
    "    props = regionprops(labeled_image)\n",
    "    return sum(prop.area for prop in props)\n",
    "\n",
    "\n",
    "def split_by_circularity(binary_mask: np.ndarray, threshold: float):\n",
    "    \"\"\"\n",
    "    Splits objects in a binary mask based on circularity.\n",
    "    \n",
    "    Parameters:\n",
    "        binary_mask (ndarray): Binary image with objects (1) and background (0).\n",
    "        threshold (float): Circularity threshold (0 to 1). Higher is more circular.\n",
    "        \n",
    "    Returns:\n",
    "        circular_mask (ndarray): Mask of objects above threshold.\n",
    "        non_circular_mask (ndarray): Mask of objects below or equal to threshold.\n",
    "    \"\"\"\n",
    "    labeled = label(binary_mask)\n",
    "    circular_mask = np.zeros_like(binary_mask, dtype=bool)\n",
    "    non_circular_mask = np.zeros_like(binary_mask, dtype=bool)\n",
    "\n",
    "    for region in regionprops(labeled):\n",
    "\n",
    "        perimeter = region.perimeter or 1  # Avoid divide-by-zero\n",
    "        circularity = 4 * np.pi * region.area / (perimeter ** 2)\n",
    "\n",
    "        if circularity > threshold:\n",
    "            circular_mask[labeled == region.label] = True\n",
    "        else:\n",
    "            non_circular_mask[labeled == region.label] = True\n",
    "\n",
    "    return circular_mask, non_circular_mask\n",
    "\n",
    "def segment_cells(green_channel):\n",
    "    \"\"\"\n",
    "    Segment whole cells in the green channel using Cellpose.\n",
    "    - Normalizes image intensity.\n",
    "    - Suppresses bright spots (e.g., inclusions) to better detect cell boundaries.\n",
    "    - Applies Gaussian blur for smoother segmentation input.\n",
    "    - Gradually increases segmentation diameter until at least one cell is detected.\n",
    "    \"\"\"\n",
    "    green_channel = normalize_image(green_channel)\n",
    "    percentile_99 = np.percentile(green_channel, 99)\n",
    "    \n",
    "    # Suppress very bright pixels (inclusions)\n",
    "    green_channel_remove_inclusions = np.where(green_channel < percentile_99, green_channel, percentile_99)\n",
    "    green_channel_remove_inclusions = gaussian(green_channel_remove_inclusions, sigma=5)\n",
    "\n",
    "    # Normalize again after processing\n",
    "    green_channel_remove_inclusions = normalize_image(green_channel_remove_inclusions)\n",
    "\n",
    "    # Try different diameters until cells are detected\n",
    "    diameter = 150\n",
    "    while diameter < 500:\n",
    "        masks, flows, styles, diams = model.eval(green_channel_remove_inclusions, diameter=diameter, channels=[0, 0])\n",
    "        labeled_cells = label(masks)\n",
    "        if np.max(labeled_cells) > 0:\n",
    "            return labeled_cells\n",
    "        diameter += 25\n",
    "\n",
    "    # No cells found\n",
    "    return None\n",
    "\n",
    "def extract_inclusions(green_channel, mask, display_graph=False):\n",
    "    \"\"\"\n",
    "    Extract potential inclusions inside a cell.\n",
    "    - Blurs and masks the cell region.\n",
    "    - Computes intensity statistics for thresholding.\n",
    "    - Applies different threshold strategies depending on intensity distribution.\n",
    "    - Removes objects that are too small or too large to be inclusions.\n",
    "    - Optionally shows histogram for debugging.\n",
    "    \"\"\"\n",
    "    applied_mask_blurred = gaussian(green_channel, sigma=1) * mask\n",
    "    applied_mask_eliminate_background = applied_mask_blurred[applied_mask_blurred > 0]\n",
    "\n",
    "    # Normalize the signal within the masked region\n",
    "    applied_mask_eliminate_background = normalize_image(applied_mask_eliminate_background)\n",
    "\n",
    "\n",
    "    # Compute descriptive statistics for intensity distribution\n",
    "    q3 = np.percentile(applied_mask_eliminate_background, 75)\n",
    "    hist, bin_edges = np.histogram(applied_mask_eliminate_background, bins='fd')\n",
    "    applied_mask = normalize_image(green_channel) * mask\n",
    "\n",
    "\n",
    "    # Decide on thresholding strategy based on upper quartile\n",
    "    if q3 < 0.4 and len(bin_edges) > 20:\n",
    "        #threshold = max(threshold_otsu(applied_mask), 0.5)\n",
    "        threshold = max(threshold_otsu(applied_mask), 0.5)\n",
    "    else:\n",
    "        threshold = 0.95\n",
    "\n",
    "    # Apply threshold and size-based filters\n",
    "    #threshold = max(threshold_otsu(applied_mask), 0.38)\n",
    "    inclusions = applied_mask > threshold\n",
    "    inclusions = remove_small_objects(inclusions, min_size=MIN_INCLUSION_SIZE)\n",
    "    #inclusions = inclusions ^ remove_small_objects(inclusions, min_size=MAX_INCLUSION_SIZE)\n",
    "\n",
    "\n",
    "    # Optional histogram display\n",
    "    if display_graph:\n",
    "        print(\"Threshold: \", threshold)\n",
    "        print(\"Bin count\", len(bin_edges))\n",
    "        plt.hist(applied_mask_eliminate_background, bins='fd')\n",
    "        plt.axvline(q3, color='purple', linestyle='dashed', linewidth=2, label=f'Q3: {q3:.2f}')\n",
    "        plt.legend()\n",
    "        plt.title(\"Intensity histogram\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return inclusions\n",
    "\n",
    "def generate_inclusion_image(green_channel, labeled_cells):\n",
    "    \"\"\"\n",
    "    Generate a binary image with all inclusions from all cells.\n",
    "    - Loops through each segmented cell.\n",
    "    - Extracts inclusions from each cell region.\n",
    "    - Combines all into one final binary image.\n",
    "    \"\"\"\n",
    "    inclusion_image = np.zeros_like(green_channel)\n",
    "\n",
    "    for i, cell in enumerate(regionprops(labeled_cells)):\n",
    "        if cell.area < 100:\n",
    "            continue\n",
    "        mask = labeled_cells == cell.label\n",
    "        inclusions = extract_inclusions(green_channel, mask)\n",
    "        inclusion_image += inclusions  # adds binary inclusion mask\n",
    "\n",
    "    return inclusion_image\n",
    "\n",
    "\n",
    "def filter_objects_by_overlap(source_mask, target_mask):\n",
    "    \"\"\"\n",
    "    Keeps objects in `source_mask` that overlap with `target_mask`.\n",
    "\n",
    "    Parameters:\n",
    "        source_mask (ndarray): Binary mask with objects to test (e.g. clustered mitochondria).\n",
    "        target_mask (ndarray): Binary mask defining inclusion region.\n",
    "\n",
    "    Returns:\n",
    "        filtered_mask (ndarray): Binary mask of source objects overlapping with target.\n",
    "    \"\"\"\n",
    "    labeled_source = label(source_mask)\n",
    "    filtered_mask = np.zeros_like(source_mask, dtype=bool)\n",
    "\n",
    "    for region in regionprops(labeled_source):\n",
    "        coords = tuple(region.coords.T)\n",
    "        if np.any(target_mask[coords]):\n",
    "            filtered_mask[coords] = True\n",
    "\n",
    "    return filtered_mask\n",
    "\n",
    "\n",
    "def get_overlapping_objects_mask(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Given two labeled masks (mask1 and mask2), return a binary mask containing\n",
    "    all objects from both masks that overlap with each other.\n",
    "    \n",
    "    Parameters:\n",
    "        mask1 (ndarray): Labeled mask (e.g., from skimage.label).\n",
    "        mask2 (ndarray): Labeled mask.\n",
    "    \n",
    "    Returns:\n",
    "        overlapping_mask (ndarray): Binary mask of the overlapping objects from both inputs.\n",
    "    \"\"\"\n",
    "    overlap = (mask1 > 0) & (mask2 > 0)\n",
    "    if not np.any(overlap):\n",
    "        return np.zeros_like(mask1, dtype=np.uint8)  # No overlap\n",
    "\n",
    "    overlapping_labels_1 = np.unique(mask1[overlap])\n",
    "    overlapping_labels_2 = np.unique(mask2[overlap])\n",
    "\n",
    "    # Create masks for overlapping objects\n",
    "    mask1_overlap = np.isin(mask1, overlapping_labels_1)\n",
    "    mask2_overlap = np.isin(mask2, overlapping_labels_2)\n",
    "\n",
    "    combined_overlap_mask = mask1_overlap | mask2_overlap\n",
    "    return combined_overlap_mask.astype(np.uint8)\n",
    "\n",
    "def calculate_densities(inclusion_image, cell, channel):\n",
    "    mask = cell > 0\n",
    "    # dilate inclusion_image\n",
    "    channel = channel * mask\n",
    "    dilated_inclusion_image = binary_dilation(inclusion_image, disk(RADIUS))\n",
    "    dilated_inclusion_image = dilated_inclusion_image * mask\n",
    "    dilated_inclusion_image_donut = dilated_inclusion_image.astype(bool) ^ inclusion_image.astype(bool)\n",
    "    overlap_with_channel = channel * dilated_inclusion_image_donut\n",
    "    surface_area_overlap_within_donut = calculate_surface_area(label(overlap_with_channel))\n",
    "\n",
    "    #display_image(inclusion_image, \"inclusion_image\", \"mask\")\n",
    "    #display_image(binary_dilation(inclusion_image, disk(RADIUS)), \"dilated_inclusion_image\", \"mask\")\n",
    "    #display_image(mask, \"mask\", \"mask\")\n",
    "    #display_image(dilated_inclusion_image, \"dilated_inclusion_image\", \"mask\")\n",
    "    #display_image(dilated_inclusion_image_donut, \"dilated_inclusion_image_donut\", \"mask\")\n",
    "\n",
    "\n",
    "    cell_without_dilated_inclusions = mask ^ dilated_inclusion_image\n",
    "    overlap_with_rest_of_the_cells = channel * cell_without_dilated_inclusions\n",
    "    surface_area_overlap_without_donut = calculate_surface_area(label(overlap_with_rest_of_the_cells))\n",
    "    #display_image(cell_without_dilated_inclusions, \"cell_without_dilated_inclusions\", \"mask\")\n",
    "    #display_image(overlap_with_channel, \"overlap_with_channel\", \"mask\")\n",
    "    #display_image(overlap_with_rest_of_the_cells, \"overlap_with_rest_of_the_cells\", \"mask\")\n",
    "    \n",
    "\n",
    "    return surface_area_overlap_within_donut, surface_area_overlap_without_donut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6662fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dox_analysis(red:np.ndarray, orange:np.ndarray, green:np.ndarray, path:str) -> pd.DataFrame:\n",
    "    data = []\n",
    "    df_cell_summary = pd.DataFrame()\n",
    "\n",
    "    print(f\"Starting analysis on {path}\")\n",
    "\n",
    "    # Preprocess the green channel\n",
    "    green = preprocess_green_channel(green)\n",
    "\n",
    "    \n",
    "\n",
    "    #return green\n",
    "\n",
    "    labeled_cells = segment_cells(green)\n",
    "    #display_image(labeled_cells, path, \"Labeled Cells\")\n",
    "\n",
    "    inclusion_image = generate_inclusion_image(green, labeled_cells)\n",
    "\n",
    "    #display_two_images(green, inclusion_image, \"Green Channel\", \"Inclusion Image\", path)\n",
    "\n",
    "    contrast_adjusted_red_normalized = (red - red.min()) / (red.max() - red.min())\n",
    "    threshold_value_red= np.mean(contrast_adjusted_red_normalized) + (np.std(contrast_adjusted_red_normalized) * 3) #1.75 works well\n",
    "    red_thresholded = contrast_adjusted_red_normalized > threshold_value_red\n",
    "    red_thresholded = remove_small_objects(red_thresholded, min_size=10)\n",
    "    #display_two_images(red, red_thresholded, \"Red Channel\", \"Red Thresholded\", path)\n",
    "\n",
    "\n",
    "    #contrast_adjusted_blue_normalized = (blue - blue.min()) / (blue.max() - blue.min())\n",
    "    #threshold_value_blue= np.mean(contrast_adjusted_blue_normalized) + (np.std(contrast_adjusted_blue_normalized) * 1.5) #1.75 works well\n",
    "    #blue_thresholded = contrast_adjusted_blue_normalized > threshold_value_blue\n",
    "    #blue_thresholded = remove_small_objects(blue_thresholded, min_size=10)\n",
    "    if ('mitotracker_farred_FCCP' in path): \n",
    "        contrast_adjusted_orange_normalized = (orange - orange.min()) / (orange.max() - orange.min())\n",
    "        threshold_value_orange= np.mean(contrast_adjusted_orange_normalized) + (np.std(contrast_adjusted_orange_normalized) * 4) #1.75 works well\n",
    "        orange_thresholded = contrast_adjusted_orange_normalized > threshold_value_orange\n",
    "        orange_thresholded = remove_small_objects(orange_thresholded, min_size=10)\n",
    "    else:\n",
    "        threshold_value_orange  = threshold_otsu(orange)\n",
    "        orange_thresholded = orange > threshold_value_orange\n",
    "    #display_two_images(blue, blue_thresholded, \"Blue Channel\", \"Blue Thresholded\", path)\n",
    "\n",
    "    cell_count = 1\n",
    "    for i, cell in enumerate(regionprops(labeled_cells)):\n",
    "        if cell.area < 100:  # Skip tiny regions likely to be noise\n",
    "            continue\n",
    "\n",
    "                # Create a mask for the current cell\n",
    "        mask = labeled_cells == cell.label\n",
    "\n",
    "        #inclusion within cell\n",
    "        inclusion_mask = inclusion_image * mask\n",
    "        red_mask = red_thresholded * mask\n",
    "        orange_mask = orange_thresholded * mask\n",
    "\n",
    "        red_surface_area = calculate_surface_area(label(red_mask))\n",
    "        orange_surface_area = calculate_surface_area(label(orange_mask))\n",
    "\n",
    "        red_surface_area_within_donut, red_surface_area_without_donut = calculate_densities(inclusion_mask, mask, red_thresholded)\n",
    "        orange_surface_area_within_donut, orange_surface_area_without_donut = calculate_densities(inclusion_mask, mask, orange_thresholded)\n",
    "\n",
    "        orange_red_overlap = get_overlapping_objects_mask(label(red_mask), label(orange_mask))\n",
    "\n",
    "        orange_red_overlap_surface_area = calculate_surface_area(orange_red_overlap)\n",
    "        orange_red_overlap_surface_area_within_donut, orange_red_overlap_surface_area_without_donut = calculate_densities(inclusion_mask, mask, orange_red_overlap)\n",
    "        \n",
    "\n",
    "\n",
    "        data.append({\n",
    "            'Image Path': path,\n",
    "            'Cell Number': cell_count,\n",
    "            'Red surface area in all cell': red_surface_area,\n",
    "            'Red surface area around inclusions': red_surface_area_within_donut,\n",
    "            'Red surface area in remaining cytoplasm': red_surface_area_without_donut,\n",
    "            'Orange surface area in all cell': orange_surface_area,\n",
    "            'Orange surface area around inclusions': orange_surface_area_within_donut,\n",
    "            'Orange surface area in remaining cytoplasm': orange_surface_area_without_donut,\n",
    "            'Orange-Red Overlap surface area in all cell': orange_red_overlap_surface_area,\n",
    "            'Orange-Red Overlap surface area around inclusions': orange_red_overlap_surface_area_within_donut,\n",
    "            'Orange-Red Overlap surface area in remaining cytoplasm': orange_red_overlap_surface_area_without_donut\n",
    "        })\n",
    "        cell_count += 1\n",
    "\n",
    "    df_cell_summary = pd.DataFrame(data)\n",
    "    return df_cell_summary\n",
    "\n",
    "def no_dox_analysis(red:np.ndarray, orange:np.ndarray, green:np.ndarray, path:str) -> pd.DataFrame:\n",
    "    data = []\n",
    "    df_cell_summary = pd.DataFrame()\n",
    "\n",
    "    print(f\"Starting analysis on {path}\")\n",
    "\n",
    "\n",
    "    contrast_adjusted_red_normalized = (red - red.min()) / (red.max() - red.min())\n",
    "    threshold_value_red= np.mean(contrast_adjusted_red_normalized) + (np.std(contrast_adjusted_red_normalized) * 3) #1.75 works well\n",
    "    red_thresholded = contrast_adjusted_red_normalized > threshold_value_red\n",
    "    red_thresholded = remove_small_objects(red_thresholded, min_size=10)\n",
    "    #display_two_images(red, red_thresholded, \"Red Channel\", \"Red Thresholded\", path)\n",
    "\n",
    "\n",
    "    #contrast_adjusted_blue_normalized = (blue - blue.min()) / (blue.max() - blue.min())\n",
    "    #threshold_value_blue= np.mean(contrast_adjusted_blue_normalized) + (np.std(contrast_adjusted_blue_normalized) * 1.5) #1.75 works well\n",
    "    #blue_thresholded = contrast_adjusted_blue_normalized > threshold_value_blue\n",
    "    #blue_thresholded = remove_small_objects(blue_thresholded, min_size=10)\n",
    "    if ('mitotracker_farred_FCCP' in path): \n",
    "        contrast_adjusted_orange_normalized = (orange - orange.min()) / (orange.max() - orange.min())\n",
    "        threshold_value_orange= np.mean(contrast_adjusted_orange_normalized) + (np.std(contrast_adjusted_orange_normalized) * 4) #1.75 works well\n",
    "        orange_thresholded = contrast_adjusted_orange_normalized > threshold_value_orange\n",
    "        orange_thresholded = remove_small_objects(orange_thresholded, min_size=10)\n",
    "    else:\n",
    "        threshold_value_orange  = threshold_otsu(orange)\n",
    "        orange_thresholded = orange > threshold_value_orange\n",
    "\n",
    "    data.append({\n",
    "        'Image Path': path,\n",
    "        'Red Surface Area in all cell': calculate_surface_area(label(red_thresholded)),\n",
    "        'Orange Surface Area in all cell': calculate_surface_area(label(orange_thresholded)),\n",
    "    })\n",
    "\n",
    "    df_cell_summary = pd.DataFrame(data)\n",
    "    return df_cell_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "224fea99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_01.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_02.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_03.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_04.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_05.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_06.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_07.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_08.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_FCCP_01.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_FCCP_02.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_FCCP_03.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_FCCP_04.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_FCCP_05.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_FCCP_06.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_FCCP_07.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mitotracker_farred_FCCP_08.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_01.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_02.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_03.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_04.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_05.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_06.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_07.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_08.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_FCCP_01.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_FCCP_02.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_FCCP_03.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_FCCP_04.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_FCCP_05.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_FCCP_06.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_FCCP_07.czi\n",
      "Starting analysis on images\\3K_dox_LAMP1_RFP_mito_BFP_FCCP_08.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mitotracker_farred_01.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mitotracker_farred_02.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mitotracker_farred_03.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mitotracker_farred_04.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mitotracker_farred_05.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mitotracker_farred_06.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mitotracker_farred_07.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mitotracker_farred_08.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mito_BFP_01.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mito_BFP_02.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mito_BFP_03.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mito_BFP_04.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mito_BFP_05.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mito_BFP_06.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mito_BFP_07.czi\n",
      "Starting analysis on images\\3K_nodox_LAMP1_RFP_mito_BFP_08.czi\n"
     ]
    }
   ],
   "source": [
    "def main(image_folder):\n",
    "    images_to_analyze = extract_image_paths(image_folder)\n",
    "    output_dir = os.getcwd()\n",
    "    df_cell_summary_list_dox = []\n",
    "    df_cell_summary_list_nodox = []\n",
    "\n",
    "    for path in images_to_analyze:\n",
    "        image = read_image(path)\n",
    "        image_squeezed = np.squeeze(image) \n",
    "    \n",
    "        if 'mitotracker' in path.lower():\n",
    "            red, orange, green = extract_channels(image_squeezed)\n",
    "        else:\n",
    "            orange, green, red = extract_channels(image_squeezed)\n",
    "\n",
    "        if ('nodox' in path.lower()):\n",
    "            df_cell_summary = no_dox_analysis(red, orange, green, path)\n",
    "            df_cell_summary_list_nodox.append(df_cell_summary)\n",
    "        else:\n",
    "            df_cell_summary = dox_analysis(red, orange, green, path)\n",
    "            df_cell_summary_list_dox.append(df_cell_summary)\n",
    "\n",
    "    combined_cell_summary_df = pd.concat(df_cell_summary_list_dox, ignore_index=True)\n",
    "    output_summary_path = os.path.join(output_dir, '61825_SUMMARY_DOX.xlsx')\n",
    "    combined_cell_summary_df.to_excel(output_summary_path, index=False)\n",
    "\n",
    "    combined_cell_summary_df_nodox = pd.concat(df_cell_summary_list_nodox, ignore_index=True)\n",
    "    output_summary_path_nodox = os.path.join(output_dir, '61825_SUMMARY_NODOX.xlsx')\n",
    "    combined_cell_summary_df_nodox.to_excel(output_summary_path_nodox, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_folder = 'images'\n",
    "    main(image_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
